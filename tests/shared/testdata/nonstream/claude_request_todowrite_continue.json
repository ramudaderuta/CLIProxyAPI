{
  "metadata": {
    "user_id": "user_fd4f99d961b75986847dac6c6384694acc7cc85d457882cb25b5ea88d1330080_account__session_87c71491-56fa-4c95-8d55-61a2e969e475"
  },
  "model": "claude-sonnet-4-5-20250929",
  "system": [
    {
      "type": "text",
      "text": "You are Claude Code, Anthropic's official CLI for Claude.",
      "cache_control": {
        "type": "ephemeral"
      }
    },
    {
      "type": "text",
      "text": "\nYou are an interactive CLI tool that helps users with software engineering tasks. Use the instructions below and the tools available to you to assist the user.\n\nIMPORTANT: Assist with authorized security testing, defensive security, CTF challenges, and educational contexts. Refuse requests for destructive techniques, DoS attacks, mass targeting, supply chain compromise, or detection evasion for malicious purposes. Dual-use security tools (C2 frameworks, credential testing, exploit development) require clear authorization context: pentesting engagements, CTF competitions, security research, or defensive use cases.\nIMPORTANT: You must NEVER generate or guess URLs for the user unless you are confident that the URLs are for helping the user with programming. You may use URLs provided by the user in their messages or local files.\n\nIf the user asks for help or wants to give feedback inform them of the following:\n- /help: Get help with using Claude Code\n- To give feedback, users should report the issue at https://github.com/anthropics/claude-code/issues\n\nWhen the user directly asks about Claude Code (eg. \"can Claude Code do...\", \"does Claude Code have...\"), or asks in second person (eg. \"are you able...\", \"can you do...\"), or asks how to use a specific Claude Code feature (eg. implement a hook, write a slash command, or install an MCP server), use the WebFetch tool to gather information to answer the question from Claude Code docs. The list of available docs is available at https://docs.claude.com/en/docs/claude-code/claude_code_docs_map.md.\n\n# Tone and style\n- Only use emojis if the user explicitly requests it. Avoid using emojis in all communication unless asked.\n- Your output will be displayed on a command line interface. Your responses should be short and concise. You can use Github-flavored markdown for formatting, and will be rendered in a monospace font using the CommonMark specification.\n- Output text to communicate with the user; all text you output outside of tool use is displayed to the user. Only use tools to complete tasks. Never use tools like Bash or code comments as means to communicate with the user during the session.\n- NEVER create files unless they're absolutely necessary for achieving your goal. ALWAYS prefer editing an existing file to creating a new one. This includes markdown files.\n\n# Professional objectivity\nPrioritize technical accuracy and truthfulness over validating the user's beliefs. Focus on facts and problem-solving, providing direct, objective technical info without any unnecessary superlatives, praise, or emotional validation. It is best for the user if Claude honestly applies the same rigorous standards to all ideas and disagrees when necessary, even if it may not be what the user wants to hear. Objective guidance and respectful correction are more valuable than false agreement. Whenever there is uncertainty, it's best to investigate to find the truth first rather than instinctively confirming the user's beliefs. Avoid using over-the-top validation or excessive praise when responding to users such as \"You're absolutely right\" or similar phrases.\n\n# Task Management\nYou have access to the TodoWrite tools to help you manage and plan tasks. Use these tools VERY frequently to ensure that you are tracking your tasks and giving the user visibility into your progress.\nThese tools are also EXTREMELY helpful for planning tasks, and for breaking down larger complex tasks into smaller steps. If you do not use this tool when planning, you may forget to do important tasks - and that is unacceptable.\n\nIt is critical that you mark todos as completed as soon as you are done with a task. Do not batch up multiple tasks before marking them as completed.\n\nExamples:\n\n<example>\nuser: Run the build and fix any type errors\nassistant: I'm going to use the TodoWrite tool to write the following items to the todo list:\n- Run the build\n- Fix any type errors\n\nI'm now going to run the build using Bash.\n\nLooks like I found 10 type errors. I'm going to use the TodoWrite tool to write 10 items to the todo list.\n\nmarking the first todo as in_progress\n\nLet me start working on the first item...\n\nThe first item has been fixed, let me mark the first todo as completed, and move on to the second item...\n..\n..\n</example>\nIn the above example, the assistant completes all the tasks, including the 10 error fixes and running the build and fixing all errors.\n\n<example>\nuser: Help me write a new feature that allows users to track their usage metrics and export them to various formats\nassistant: I'll help you implement a usage metrics tracking and export feature. Let me first use the TodoWrite tool to plan this task.\nAdding the following todos to the todo list:\n1. Research existing metrics tracking in the codebase\n2. Design the metrics collection system\n3. Implement core metrics tracking functionality\n4. Create export functionality for different formats\n\nLet me start by researching the existing codebase to understand what metrics we might already be tracking and how we can build on that.\n\nI'm going to search for any existing metrics or telemetry code in the project.\n\nI've found some existing telemetry code. Let me mark the first todo as in_progress and start designing our metrics tracking system based on what I've learned...\n\n[Assistant continues implementing the feature step by step, marking todos as in_progress and completed as they go]\n</example>\n\n\n\n# Asking questions as you work\n\nYou have access to the AskUserQuestion tool to ask the user questions when you need clarification, want to validate assumptions, or need to make a decision you're unsure about.\n\n\nUsers may configure 'hooks', shell commands that execute in response to events like tool calls, in settings. Treat feedback from hooks, including <user-prompt-submit-hook>, as coming from the user. If you get blocked by a hook, determine if you can adjust your actions in response to the blocked message. If not, ask the user to check their hooks configuration.\n\n# Doing tasks\nThe user will primarily request you perform software engineering tasks. This includes solving bugs, adding new functionality, refactoring code, explaining code, and more. For these tasks the following steps are recommended:\n- Use the TodoWrite tool to plan the task if required\n- Use the AskUserQuestion tool to ask questions, clarify and gather information as needed.\n- Be careful not to introduce security vulnerabilities such as command injection, XSS, SQL injection, and other OWASP top 10 vulnerabilities. If you notice that you wrote insecure code, immediately fix it.\n\n- Tool results and user messages may include <system-reminder> tags. <system-reminder> tags contain useful information and reminders. They are automatically added by the system, and bear no direct relation to the specific tool results or user messages in which they appear.\n\n\n# Tool usage policy\n- When doing file search, prefer to use the Task tool in order to reduce context usage.\n- You should proactively use the Task tool with specialized agents when the task at hand matches the agent's description.\n\n- When WebFetch returns a message about a redirect to a different host, you should immediately make a new WebFetch request with the redirect URL provided in the response.\n- You can call multiple tools in a single response. If you intend to call multiple tools and there are no dependencies between them, make all independent tool calls in parallel. Maximize use of parallel tool calls where possible to increase efficiency. However, if some tool calls depend on previous calls to inform dependent values, do NOT call these tools in parallel and instead call them sequentially. For instance, if one operation must complete before another starts, run these operations sequentially instead. Never use placeholders or guess missing parameters in tool calls.\n- If the user specifies that they want you to run tools \"in parallel\", you MUST send a single message with multiple tool use content blocks. For example, if you need to launch multiple agents in parallel, send a single message with multiple Task tool calls.\n- Use specialized tools instead of bash commands when possible, as this provides a better user experience. For file operations, use dedicated tools: Read for reading files instead of cat/head/tail, Edit for editing instead of sed/awk, and Write for creating files instead of cat with heredoc or echo redirection. Reserve bash tools exclusively for actual system commands and terminal operations that require shell execution. NEVER use bash echo or other command-line tools to communicate thoughts, explanations, or instructions to the user. Output all communication directly in your response text instead.\n- VERY IMPORTANT: When exploring the codebase to gather context or to answer a question that is not a needle query for a specific file/class/function, it is CRITICAL that you use the Task tool with subagent_type=Explore instead of running search commands directly.\n<example>\nuser: Where are errors from the client handled?\nassistant: [Uses the Task tool with subagent_type=Explore to find the files that handle client errors instead of using Glob or Grep directly]\n</example>\n<example>\nuser: What is the codebase structure?\nassistant: [Uses the Task tool with subagent_type=Explore]\n</example>\n\n\n\nHere is useful information about the environment you are running in:\n<env>\nWorking directory: /home/build/.claude/agents\nIs directory a git repo: Yes\nPlatform: linux\nOS Version: Linux 6.6.87.2-microsoft-standard-WSL2\nToday's date: 2025-11-13\n</env>\nYou are powered by the model named Sonnet 4.5. The exact model ID is claude-sonnet-4-5-20250929.\n\nAssistant knowledge cutoff is January 2025.\n\n<claude_background_info>\nThe most recent frontier Claude model is Claude Sonnet 4.5 (model ID: 'claude-sonnet-4-5-20250929').\n</claude_background_info>\n\n\nIMPORTANT: Assist with authorized security testing, defensive security, CTF challenges, and educational contexts. Refuse requests for destructive techniques, DoS attacks, mass targeting, supply chain compromise, or detection evasion for malicious purposes. Dual-use security tools (C2 frameworks, credential testing, exploit development) require clear authorization context: pentesting engagements, CTF competitions, security research, or defensive use cases.\n\n\nIMPORTANT: Always use the TodoWrite tool to plan and track tasks throughout the conversation.\n\n# Code References\n\nWhen referencing specific functions or pieces of code include the pattern `file_path:line_number` to allow the user to easily navigate to the source code location.\n\n<example>\nuser: Where are errors from the client handled?\nassistant: Clients are marked as failed in the `connectToServer` function in src/services/process.ts:712.\n</example>\n\ngitStatus: This is the git status at the start of the conversation. Note that this status is a snapshot in time, and will not update during the conversation.\nCurrent branch: feature-new-branch\n\nMain branch (you will usually use this for PRs): \n\nStatus:\n?? skills-consolidation.md\n\nRecent commits:\n47cba92 feat: add consolidated expert agents and categorization docs\n4edbbbf feat: add specialized Claude Code role configs\n72bf9ad feat: add specialized Claude Code role configs\naa85752 feat: add commit-writer agent configuration",
      "cache_control": {
        "type": "ephemeral"
      }
    }
  ],
  "messages": [
    {
      "role": "user",
      "content": "<system-reminder>\nCalled the Read tool with the following input: {\"file_path\":\"/home/build/.claude/agents/_consolidation/SUBAGENTS_CATEGORIZATION.md\"}\n</system-reminder>"
    },
    {
      "role": "user",
      "content": [
        {
          "type": "text",
          "text": "<system-reminder>\nResult of calling the Read tool: \"     1\u2192# Sub-Agents Categorization\\n     2\u2192\\n     3\u2192This document organizes all 88 sub-agents into logical categories for consolidation analysis.\\n     4\u2192\\n     5\u2192## Overview\\n     6\u2192\\n     7\u2192**Total Sub-Agents**: 88\\n     8\u2192**Categories Identified**: 21 (split programming languages into 4 groups)\\n     9\u2192\\n    10\u2192---\\n    11\u2192\\n    12\u2192## Category 1: Architecture & Design (8 sub-agents)\\n    13\u2192\\n    14\u2192**Purpose**: System architecture, design patterns, and architectural reviews\\n    15\u2192\\n    16\u2192### Sub-agents:\\n    17\u21921. **architect-review.md** - Master software architect specializing in modern architecture patterns, clean architecture, microservices, event-driven systems, and DDD\\n    18\u21922. **backend-architect.md** - Expert backend architect specializing in scalable API design, microservices architecture, and distributed systems\\n    19\u21923. **cloud-architect.md** - Expert cloud architect specializing in AWS/Azure/GCP multi-cloud infrastructure design, advanced IaC, FinOps cost optimization\\n    20\u21924. **hybrid-cloud-architect.md** - Expert hybrid cloud architect specializing in complex multi-cloud solutions across AWS/Azure/GCP and private clouds\\n    21\u21925. **kubernetes-architect.md** - Expert Kubernetes architect specializing in cloud-native infrastructure, advanced GitOps workflows, and enterprise container orchestration\\n    22\u21926. **graphql-architect.md** - Master modern GraphQL with federation, performance optimization, and enterprise security\\n    23\u21927. **database-architect.md** - Expert database architect specializing in data layer design from scratch, technology selection, schema modeling\\n    24\u21928. **docs-architect.md** - Creates comprehensive technical documentation from existing codebases\\n    25\u2192\\n    26\u2192**Consolidation Potential**: HIGH - Significant overlap in architecture principles, design patterns, and system design approaches\\n    27\u2192\\n    28\u2192---\\n    29\u2192\\n    30\u2192## Category 2A: Systems Programming Languages (5 sub-agents)\\n    31\u2192\\n    32\u2192**Purpose**: Low-level, performance-critical systems programming\\n    33\u2192\\n    34\u2192### Sub-agents:\\n    35\u21921. **rust-pro.md** - Master Rust 1.75+ with modern async patterns, advanced type system features\\n    36\u21922. **cpp-pro.md** - Write idiomatic C++ code with modern features, RAII, smart pointers, and STL algorithms\\n    37\u21923. **c-pro.md** - Write efficient C code with proper memory management, pointer arithmetic, and system calls\\n    38\u21924. **golang-pro.md** - Master Go 1.21+ with modern patterns, advanced concurrency, performance optimization\\n    39\u21925. **julia-pro.md** - Master Julia 1.10+ with modern features, performance optimization, multiple dispatch\\n    40\u2192\\n    41\u2192**Consolidation Potential**: LOW - Each language has distinct use cases and ecosystems\\n    42\u2192\\n    43\u2192---\\n    44\u2192\\n    45\u2192## Category 2B: Enterprise & JVM Languages (3 sub-agents)\\n    46\u2192\\n    47\u2192**Purpose**: Enterprise application development and JVM ecosystem\\n    48\u2192\\n    49\u2192### Sub-agents:\\n    50\u21921. **java-pro.md** - Master Java 21+ with modern features like virtual threads, pattern matching, and Spring Boot 3.x\\n    51\u21922. **scala-pro.md** - Master enterprise-grade Scala development with functional programming, distributed systems\\n    52\u21923. **csharp-pro.md** - Write modern C# code with advanced features like records, pattern matching, and async/await\\n    53\u2192\\n    54\u2192**Consolidation Potential**: LOW - Different ecosystems (.NET vs JVM) and paradigms\\n    55\u2192\\n    56\u2192---\\n    57\u2192\\n    58\u2192## Category 2C: Web & Scripting Languages (7 sub-agents)\\n    59\u2192\\n    60\u2192**Purpose**: Web development, scripting, and dynamic languages\\n    61\u2192\\n    62\u2192### Sub-agents:\\n    63\u21921. **python-pro.md** - Master Python 3.12+ with modern features, async programming, performance optimization\\n    64\u21922. **javascript-pro.md** - Master modern JavaScript with ES6+, async patterns, and Node.js APIs\\n    65\u21923. **typescript-pro.md** - Master TypeScript with advanced types, generics, and strict type safety\\n    66\u21924. **ruby-pro.md** - Write idiomatic Ruby code with metaprogramming, Rails patterns, and performance optimization\\n    67\u21925. **php-pro.md** - Write idiomatic PHP code with generators, iterators, SPL data structures, and modern OOP features\\n    68\u21926. **elixir-pro.md** - Write idiomatic Elixir code with OTP patterns, supervision trees, and Phoenix LiveView\\n    69\u21927. **sql-pro.md** - Master modern SQL with cloud-native databases, OLTP/OLAP optimization\\n    70\u2192\\n    71\u2192**Consolidation Potential**: LOW - Each has distinct ecosystems, but could merge bash/posix shell scripts\\n    72\u2192\\n    73\u2192---\\n    74\u2192\\n    75\u2192## Category 2D: Framework & Platform Specialists (8 sub-agents)\\n    76\u2192\\n    77\u2192**Purpose**: Framework-specific and platform-specific development\\n    78\u2192\\n    79\u2192### Sub-agents:\\n    80\u21921. **fastapi-pro.md** - Build high-performance async APIs with FastAPI, SQLAlchemy 2.0, and Pydantic V2\\n    81\u21922. **django-pro.md** - Master Django 5.x with async views, DRF, Celery, and Django Channels\\n    82\u21923. **flutter-expert.md** - Master Flutter development with Dart 3, advanced widgets, and multi-platform deployment\\n    83\u21924. **ios-developer.md** - Develop native iOS applications with Swift/SwiftUI\\n    84\u21925. **unity-developer.md** - Build Unity games with optimized C# scripts, efficient rendering\\n    85\u21926. **minecraft-bukkit-pro.md** - Master Minecraft server plugin development with Bukkit, Spigot, and Paper APIs\\n    86\u21927. **bash-pro.md** - Master of defensive Bash scripting for production automation, CI/CD pipelines\\n    87\u21928. **posix-shell-pro.md** - Expert in strict POSIX sh scripting for maximum portability across Unix-like systems\\n    88\u2192\\n    89\u2192**Consolidation Potential**: MEDIUM - Could merge bash-pro and posix-shell-pro (2 \u2192 1)\\n    90\u2192\\n    91\u2192---\\n    92\u2192\\n    93\u2192## Category 3: Security (5 sub-agents)\\n    94\u2192\\n    95\u2192**Purpose**: Security auditing, secure coding practices, and compliance\\n    96\u2192\\n    97\u2192### Sub-agents:\\n    98\u21921. **security-auditor.md** - Expert security auditor specializing in DevSecOps, comprehensive cybersecurity, and compliance frameworks\\n    99\u21922. **backend-security-coder.md** - Expert in secure backend coding practices specializing in input validation, authentication, and API security\\n   100\u21923. **frontend-security-coder.md** - Expert in secure frontend coding practices specializing in XSS prevention, output sanitization\\n   101\u21924. **mobile-security-coder.md** - Expert in secure mobile coding practices specializing in input validation, WebView security\\n   102\u21925. **network-engineer.md** - Expert network engineer specializing in modern cloud networking, security architectures\\n   103\u2192\\n   104\u2192**Consolidation Potential**: MEDIUM - Could consolidate security-coder agents into one comprehensive secure coding expert\\n   105\u2192\\n   106\u2192---\\n   107\u2192\\n   108\u2192## Category 4: Testing & Quality Assurance (4 sub-agents)\\n   109\u2192\\n   110\u2192**Purpose**: Testing strategies, test automation, and quality engineering\\n   111\u2192\\n   112\u2192### Sub-agents:\\n   113\u21921. **test-automator.md** - Master AI-powered test automation with modern frameworks, self-healing tests\\n   114\u21922. **tdd-orchestrator.md** - Master TDD orchestrator specializing in red-green-refactor discipline\\n   115\u21923. **ui-visual-validator.md** - Rigorous visual validation expert specializing in UI testing, design system compliance\\n   116\u21924. **code-reviewer.md** - Elite code review expert specializing in modern AI-powered code analysis\\n   117\u2192\\n   118\u2192**Consolidation Potential**: MEDIUM - Could merge test-automator and tdd-orchestrator\\n   119\u2192\\n   120\u2192---\\n   121\u2192\\n   122\u2192## Category 5: Database Operations (3 sub-agents)\\n   123\u2192\\n   124\u2192**Purpose**: Database administration, optimization, and management\\n   125\u2192\\n   126\u2192### Sub-agents:\\n   127\u21921. **database-admin.md** - Expert database administrator specializing in modern cloud databases, automation\\n   128\u21922. **database-optimizer.md** - Expert database optimizer specializing in modern performance tuning, query optimization\\n   129\u21923. **database-architect.md** - Expert database architect specializing in data layer design from scratch (also in Architecture)\\n   130\u2192\\n   131\u2192**Consolidation Potential**: HIGH - Significant overlap in database expertise\\n   132\u2192\\n   133\u2192---\\n   134\u2192\\n   135\u2192## Category 6: DevOps & Infrastructure (5 sub-agents)\\n   136\u2192\\n   137\u2192**Purpose**: CI/CD, deployment, infrastructure automation, and troubleshooting\\n   138\u2192\\n   139\u2192### Sub-agents:\\n   140\u21921. **deployment-engineer.md** - Expert deployment engineer specializing in modern CI/CD pipelines, GitOps workflows\\n   141\u21922. **devops-troubleshooter.md** - Expert DevOps troubleshooter specializing in rapid incident response, advanced debugging\\n   142\u21923. **terraform-specialist.md** - Expert Terraform/OpenTofu specialist mastering advanced IaC automation\\n   143\u21924. **incident-responder.md** - Expert SRE incident responder specializing in rapid problem resolution\\n   144\u21925. **observability-engineer.md** - Build production-ready monitoring, logging, and tracing systems\\n   145\u2192\\n   146\u2192**Consolidation Potential**: MEDIUM - Could merge deployment-engineer and devops-troubleshooter\\n   147\u2192\\n   148\u2192---\\n   149\u2192\\n   150\u2192## Category 7: AI & Machine Learning (6 sub-agents)\\n   151\u2192\\n   152\u2192**Purpose**: AI/ML development, MLOps, and AI system design\\n   153\u2192\\n   154\u2192### Sub-agents:\\n   155\u21921. **ai-engineer.md** - Build production-ready LLM applications, advanced RAG systems, and intelligent agents\\n   156\u21922. **ml-engineer.md** - Build production ML systems with PyTorch 2.x, TensorFlow, and modern ML frameworks\\n   157\u21923. **mlops-engineer.md** - Build comprehensive ML pipelines, experiment tracking, and model registries\\n   158\u21924. **prompt-engineer.md** - Expert prompt engineer specializing in advanced prompting techniques, LLM optimization\\n   159\u21925. **context-manager.md** - Elite AI context engineering specialist mastering dynamic context management\\n   160\u21926. **data-scientist.md** - Expert data scientist for advanced analytics, machine learning, and statistical modeling\\n   161\u2192\\n   162\u2192**Consolidation Potential**: MEDIUM - Could merge ml-engineer and mlops-engineer\\n   163\u2192\\n   164\u2192---\\n   165\u2192\\n   166\u2192## Category 8: Frontend & UI/UX (4 sub-agents)\\n   167\u2192\\n   168\u2192**Purpose**: Frontend development, UI/UX design, and visual validation\\n   169\u2192\\n   170\u2192### Sub-agents:\\n   171\u21921. **frontend-developer.md** - Build React components, implement responsive layouts, and handle client-side state management\\n   172\u21922. **ui-ux-designer.md** - Create interface designs, wireframes, and design systems\\n   173\u21923. **ui-visual-validator.md** - Rigorous visual validation expert (also in Testing)\\n   174\u21924. **mobile-developer.md** - Develop React Native, Flutter, or native mobile apps\\n   175\u2192\\n   176\u2192**Consolidation Potential**: LOW - Distinct roles with different focuses\\n   177\u2192\\n   178\u2192---\\n   179\u2192\\n   180\u2192## Category 9: Data Engineering & Analytics (2 sub-agents)\\n   181\u2192\\n   182\u2192**Purpose**: Data pipelines, warehouses, and analytics infrastructure\\n   183\u2192\\n   184\u2192### Sub-agents:\\n   185\u21921. **data-engineer.md** - Build scalable data pipelines, modern data warehouses, and real-time streaming architectures\\n   186\u21922. **data-scientist.md** - Expert data scientist for advanced analytics (also in AI/ML)\\n   187\u2192\\n   188\u2192**Consolidation Potential**: LOW - Complementary but distinct roles\\n   189\u2192\\n   190\u2192---\\n   191\u2192\\n   192\u2192## Category 10: Debugging & Troubleshooting (3 sub-agents)\\n   193\u2192\\n   194\u2192**Purpose**: Error detection, debugging, and root cause analysis\\n   195\u2192\\n   196\u2192### Sub-agents:\\n   197\u21921. **debugger.md** - Debugging specialist for errors, test failures, and unexpected behavior\\n   198\u21922. **error-detective.md** - Search logs and codebases for error patterns, stack traces, and anomalies\\n   199\u21923. **devops-troubleshooter.md** - Expert DevOps troubleshooter (also in DevOps)\\n   200\u2192\\n   201\u2192**Consolidation Potential**: HIGH - Could merge debugger and error-detective\\n   202\u2192\\n   203\u2192---\\n   204\u2192\\n   205\u2192## Category 11: Performance & Optimization (2 sub-agents)\\n   206\u2192\\n   207\u2192**Purpose**: Performance engineering and optimization\\n   208\u2192\\n   209\u2192### Sub-agents:\\n   210\u21921. **performance-engineer.md** - Expert performance engineer specializing in modern observability, application optimization\\n   211\u21922. **database-optimizer.md** - Expert database optimizer (also in Database Operations)\\n   212\u2192\\n   213\u2192**Consolidation Potential**: LOW - Different optimization domains\\n   214\u2192\\n   215\u2192---\\n   216\u2192\\n   217\u2192## Category 12: Documentation & Content (7 sub-agents)\\n   218\u2192\\n   219\u2192**Purpose**: Documentation, content creation, and technical writing\\n   220\u2192\\n   221\u2192### Sub-agents:\\n   222\u21921. **api-documenter.md** - Master API documentation with OpenAPI 3.1, AI-powered tools\\n   223\u21922. **docs-architect.md** - Creates comprehensive technical documentation (also in Architecture)\\n   224\u21923. **reference-builder.md** - Creates exhaustive technical references and API documentation\\n   225\u21924. **tutorial-engineer.md** - Creates step-by-step tutorials and educational content from code\\n   226\u21925. **mermaid-expert.md** - Create Mermaid diagrams for flowcharts, sequences, ERDs, and architectures\\n   227\u21926. **content-marketer.md** - Elite content marketing strategist specializing in AI-powered content creation\\n   228\u21927. **search-specialist.md** - Expert web researcher using advanced search techniques and synthesis\\n   229\u2192\\n   230\u2192**Consolidation Potential**: MEDIUM - Could merge api-documenter and reference-builder\\n   231\u2192\\n   232\u2192---\\n   233\u2192\\n   234\u2192## Category 13: SEO & Content Marketing (10 sub-agents)\\n   235\u2192\\n   236\u2192**Purpose**: SEO optimization, content strategy, and search marketing\\n   237\u2192\\n   238\u2192### Sub-agents:\\n   239\u21921. **seo-content-writer.md** - Writes SEO-optimized content based on provided keywords\\n   240\u21922. **seo-content-planner.md** - Creates comprehensive content outlines and topic clusters for SEO\\n   241\u21923. **seo-content-auditor.md** - Analyzes provided content for quality, E-E-A-T signals\\n   242\u21924. **seo-content-refresher.md** - Identifies outdated elements in provided content\\n   243\u21925. **seo-keyword-strategist.md** - Analyzes keyword usage in provided content\\n   244\u21926. **seo-meta-optimizer.md** - Creates optimized meta titles, descriptions, and URL suggestions\\n   245\u21927. **seo-snippet-hunter.md** - Formats content to be eligible for featured snippets\\n   246\u21928. **seo-structure-architect.md** - Analyzes and optimizes content structure\\n   247\u21929. **seo-authority-builder.md** - Analyzes content for E-E-A-T signals\\n   248\u219210. **seo-cannibalization-detector.md** - Analyzes multiple pages to identify keyword overlap\\n   249\u2192\\n   250\u2192**Consolidation Potential**: VERY HIGH - All SEO agents could consolidate into 2-3 comprehensive SEO experts\\n   251\u2192\\n   252\u2192---\\n   253\u2192\\n   254\u2192## Category 14: Blockchain & Web3 (1 sub-agent)\\n   255\u2192\\n   256\u2192**Purpose**: Blockchain development and Web3 applications\\n   257\u2192\\n   258\u2192### Sub-agents:\\n   259\u21921. **blockchain-developer.md** - Build production-ready Web3 applications, smart contracts, and decentralized systems\\n   260\u2192\\n   261\u2192**Consolidation Potential**: N/A - Single agent\\n   262\u2192\\n   263\u2192---\\n   264\u2192\\n   265\u2192## Category 15: Business & Finance (5 sub-agents)\\n   266\u2192\\n   267\u2192**Purpose**: Business analysis, finance, HR, and sales\\n   268\u2192\\n   269\u2192### Sub-agents:\\n   270\u21921. **business-analyst.md** - Master modern business analysis with AI-powered analytics\\n   271\u21922. **quant-analyst.md** - Build financial models, backtest trading strategies\\n   272\u21923. **risk-manager.md** - Monitor portfolio risk, R-multiples, and position limits\\n   273\u21924. **hr-pro.md** - Professional, ethical HR partner for hiring, onboarding/offboarding\\n   274\u21925. **sales-automator.md** - Draft cold emails, follow-ups, and proposal templates\\n   275\u2192\\n   276\u2192**Consolidation Potential**: LOW - Distinct business domains\\n   277\u2192\\n   278\u2192---\\n   279\u2192\\n   280\u2192## Category 16: Specialized Hardware/Embedded (1 sub-agent)\\n   281\u2192\\n   282\u2192**Purpose**: Embedded systems and hardware-specific development\\n   283\u2192\\n   284\u2192### Sub-agents:\\n   285\u21921. **arm-cortex-expert.md** - ARM Cortex embedded systems expert\\n   286\u2192\\n   287\u2192**Consolidation Potential**: N/A - Single agent\\n   288\u2192\\n   289\u2192---\\n   290\u2192\\n   291\u2192## Category 17: Customer Experience (2 sub-agents)\\n   292\u2192\\n   293\u2192**Purpose**: Customer support and experience management\\n   294\u2192\\n   295\u2192### Sub-agents:\\n   296\u21921. **customer-support.md** - Elite AI-powered customer support specialist\\n   297\u21922. **legal-advisor.md** - Draft privacy policies, terms of service, disclaimers\\n   298\u2192\\n   299\u2192**Consolidation Potential**: LOW - Different domains\\n   300\u2192\\n   301\u2192---\\n   302\u2192\\n   303\u2192## Category 18: Developer Experience & Tools (3 sub-agents)\\n   304\u2192\\n   305\u2192**Purpose**: Developer productivity, tooling, and workflow optimization\\n   306\u2192\\n   307\u2192### Sub-agents:\\n   308\u21921. **dx-optimizer.md** - Developer Experience specialist\\n   309\u21922. **legacy-modernizer.md** - Refactor legacy codebases, migrate outdated frameworks\\n   310\u21923. **payment-integration.md** - Integrate Stripe, PayPal, and payment processors\\n   311\u2192\\n   312\u2192**Consolidation Potential**: LOW - Distinct focuses\\n   313\u2192\\n   314\u2192---\\n   315\u2192\\n   316\u2192## Summary Statistics\\n   317\u2192\\n   318\u2192| Category | Sub-Agents | Consolidation Potential |\\n   319\u2192|----------|-----------|------------------------|\\n   320\u2192| Architecture & Design | 8 | HIGH |\\n   321\u2192| Systems Programming Languages | 5 | LOW |\\n   322\u2192| Enterprise & JVM Languages | 3 | LOW |\\n   323\u2192| Web & Scripting Languages | 7 | LOW |\\n   324\u2192| Framework & Platform Specialists | 8 | MEDIUM (shell scripts) |\\n   325\u2192| Security | 5 | MEDIUM |\\n   326\u2192| Testing & QA | 4 | MEDIUM |\\n   327\u2192| Database Operations | 3 | HIGH |\\n   328\u2192| DevOps & Infrastructure | 5 | MEDIUM |\\n   329\u2192| AI & Machine Learning | 6 | MEDIUM |\\n   330\u2192| Frontend & UI/UX | 4 | LOW |\\n   331\u2192| Data Engineering | 2 | LOW |\\n   332\u2192| Debugging & Troubleshooting | 3 | HIGH |\\n   333\u2192| Performance & Optimization | 2 | LOW |\\n   334\u2192| Documentation & Content | 7 | MEDIUM |\\n   335\u2192| SEO & Content Marketing | 10 | VERY HIGH |\\n   336\u2192| Blockchain & Web3 | 1 | N/A |\\n   337\u2192| Business & Finance | 5 | LOW |\\n   338\u2192| Specialized Hardware | 1 | N/A |\\n   339\u2192| Customer Experience | 2 | LOW |\\n   340\u2192| Developer Experience | 3 | LOW |\\n   341\u2192\\n   342\u2192## High-Priority Consolidation Candidates\\n   343\u2192\\n   344\u2192### 1. SEO & Content Marketing (10 \u2192 1 agent)\\n   345\u2192- **Target**: `seo-expert`\\n   346\u2192- **Rationale**: All 10 agents work on SEO with significant overlap in content optimization, keyword strategy, and technical SEO\\n   347\u2192\\n   348\u2192### 2. Architecture & Design (8 \u2192 3 agents)\\n   349\u2192- **Target**: `system-architect`, `cloud-architect`, `api-architect`\\n   350\u2192- **Rationale**: Group by clear domain boundaries - system design, cloud infrastructure, and API architecture\\n   351\u2192\\n   352\u2192### 3. Database Operations (3 \u2192 1 agent)\\n   353\u2192- **Target**: `database-expert`\\n   354\u2192- **Rationale**: Admin, optimization, and architecture are complementary aspects\\n   355\u2192\\n   356\u2192### 4. Debugging & Troubleshooting (3 \u2192 1 agent)\\n   357\u2192- **Target**: `debug-expert`\\n   358\u2192- **Rationale**: All focus on error detection and resolution\\n   359\u2192\\n   360\u2192### 5. Security Coders (3 \u2192 1 agent)\\n   361\u2192- **Target**: `security-coder-expert`\\n   362\u2192- **Rationale**: Backend, frontend, and mobile security coding share common principles\\n   363\u2192\\n   364\u2192### 6. Shell Scripting (2 \u2192 1 agent)\\n   365\u2192- **Target**: `shell-scripting-expert`\\n   366\u2192- **Rationale**: bash-pro and posix-shell-pro have overlapping shell scripting expertise\\n   367\u2192\\n   368\u2192## Estimated Consolidation Impact\\n   369\u2192\\n   370\u2192| Metric | Current | Target | Reduction |\\n   371\u2192|--------|---------|--------|-----------|\\n   372\u2192| Total Sub-Agents | 88 | ~37 | ~58% |\\n   373\u2192| SEO Agents | 10 | 1 | 90% |\\n   374\u2192| Architecture Agents | 8 | 3 | 62% |\\n   375\u2192| Database Agents | 3 | 1 | 66% |\\n   376\u2192| Security Coders | 3 | 1 | 66% |\\n   377\u2192| Debugging Agents | 3 | 1 | 66% |\\n   378\u2192| Shell Scripting | 2 | 1 | 50% |\\n   379\u2192| Testing & QA | 4 | 2 | 50% |\\n   380\u2192| DevOps & Infrastructure | 5 | 1 | 80% |\\n   381\u2192| AI & ML | 6 | 1 | 83% |\\n   382\u2192| Documentation & Content | 7 | 1 | 86% |\\n   383\u2192| Security Infrastructure | 2 | 1 | 50% |\\n   384\u2192| Data Engineering | 2 | 1 | 50% |\\n   385\u2192| Performance Optimization | 2 | 1 | 50% |\\n   386\u2192| Business & Finance | 5 | 1 | 80% |\\n   387\u2192| Customer Experience | 2 | 1 | 50% |\\n   388\u2192| Developer Experience | 3 | 1 | 66% |\\n   389\u2192| Frontend & UI/UX | 4 | 2 | 50% |\\n   390\u2192\\n\\n<system-reminder>\\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\\n</system-reminder>\\n\"\n</system-reminder>"
        },
        {
          "type": "text",
          "text": "<system-reminder>\nThis is a reminder that your todo list is currently empty. DO NOT mention this to the user explicitly because they are already aware. If you are working on tasks that would benefit from a todo list please use the TodoWrite tool to create one. If not, please feel free to ignore. Again do not mention this message to the user.\n</system-reminder>"
        },
        {
          "type": "text",
          "text": "<system-reminder>\nAs you answer the user's questions, you can use the following context:\n# claudeMd\nCodebase and user instructions are shown below. Be sure to adhere to these instructions. IMPORTANT: These instructions OVERRIDE any default behavior and you MUST follow them exactly as written.\n\nContents of /home/build/.claude/CLAUDE.md (user's private global instructions for all projects):\n\n# Claude Code: Best Practices for Effective Collaboration  \r\n  \r\nThis document outlines best practices for working with Claude Code to ensure efficient and successful software development tasks.  \r\n  \r\n## Task Management  \r\n  \r\nFor complex or multi-step tasks, Claude Code **MUST** use:  \r\n*   **TodoWrite**: To create a structured task list, breaking down the work into manageable steps. This provides clarity on the plan and allows for tracking progress.  \r\n*   **TodoRead**: To review the current list of tasks and their status, ensuring alignment and that all objectives are being addressed.  \r\n  \r\n## File Handling and Reading  \r\n  \r\nUnderstanding file content is crucial before making modifications.  \r\n  \r\n1.  **Targeted Information Retrieval**:  \r\n    *   When searching for specific content, patterns, or definitions within a codebase, prefer using search tools like `Grep` or `Task` (with a focused search prompt). This is more efficient than reading entire files.  \r\n  \r\n2.  **Reading File Content**:  \r\n    *   **Small to Medium Files**: For files where full context is needed or that are not excessively large, the `Read` tool can be used to retrieve the entire content.  \r\n    *   **Large File Strategy**:  \r\n        1.  **Assess Size**: Before reading a potentially large file, its size should be determined (e.g., using `ls -l` via the `Bash` tool or by an initial `Read` with a small `limit` to observe if content is truncated).  \r\n        2.  **Chunked Reading**: If a file is large (e.g., over a few thousand lines), it should be read in manageable chunks (e.g., 1000-2000 lines at a time) using the `offset` and `limit` parameters of the `Read` tool. This ensures all content can be processed without issues.  \r\n    *   Always ensure that the file path provided to `Read` is absolute.  \r\n  \r\n## File Editing  \r\n  \r\nPrecision is key for successful file edits. The following strategies lead to reliable modifications:  \r\n  \r\n1.  **Pre-Edit Read**: **Always** use the `Read` tool to fetch the content of the file *immediately before* attempting any `Edit` or `MultiEdit` operation. This ensures modifications are based on the absolute latest version of the file.  \r\n  \r\n2.  **Constructing `old_string` (The text to be replaced)**:  \r\n    *   **Exact Match**: The `old_string` must be an *exact* character-for-character match of the segment in the file you intend to replace. This includes all whitespace (spaces, tabs, newlines) and special characters.  \r\n    *   **No Read Artifacts**: Crucially, do *not* include any formatting artifacts from the `Read` tool's output (e.g., `cat -n` style line numbers or display-only leading tabs) in the `old_string`. It must only contain the literal characters as they exist in the raw file.  \r\n    *   **Sufficient Context & Uniqueness**: Provide enough context (surrounding lines) in `old_string` to make it uniquely identifiable at the intended edit location. The \"Anchor on a Known Good Line\" strategy is preferred: `old_string` is a larger, unique block of text surrounding the change or insertion point. This is highly reliable.  \r\n  \r\n3.  **Constructing `new_string` (The replacement text)**:  \r\n    *   **Exact Representation**: The `new_string` must accurately represent the desired state of the code, including correct indentation, whitespace, and newlines.  \r\n    *   **No Read Artifacts**: As with `old_string`, ensure `new_string` does *not* contain any `Read` tool output artifacts.  \r\n  \r\n4.  **Choosing the Right Editing Tool**:  \r\n    *   **`Edit` Tool**: Suitable for a single, well-defined replacement in a file.  \r\n    *   **`MultiEdit` Tool**: Preferred when multiple changes are needed within the same file. Edits are applied sequentially, with each subsequent edit operating on the result of the previous one. This tool is highly effective for complex modifications.  \r\n  \r\n5.  **Verification**:  \r\n    *   The success confirmation from the `Edit` or `MultiEdit` tool (especially if `expected_replacements` is used and matches) is the primary indicator that the change was made.  \r\n    *   If further visual confirmation is needed, use the `Read` tool with `offset` and `limit` parameters to view only the specific section of the file that was changed, rather than re-reading the entire file.  \r\n  \r\n### Reliable Code Insertion with MultiEdit  \r\n  \r\nWhen inserting larger blocks of new code (e.g., multiple functions or methods) where a simple `old_string` might be fragile due to surrounding code, the following `MultiEdit` strategy can be more robust:  \r\n  \r\n1.  **First Edit - Targeted Insertion Point**: For the primary code block you want to insert (e.g., new methods within a class), identify a short, unique, and stable line of code immediately *after* your desired insertion point. Use this stable line as the `old_string`.  \r\n    *   The `new_string` will consist of your new block of code, followed by a newline, and then the original `old_string` (the stable line you matched on).  \r\n    *   Example: If inserting methods into a class, the `old_string` might be the closing brace `}` of the class, or a comment that directly follows the class.  \r\n  \r\n2.  **Second Edit (Optional) - Ancillary Code**: If there's another, smaller piece of related code to insert (e.g., a function call within an existing method, or an import statement), perform this as a separate, more straightforward edit within the `MultiEdit` call. This edit usually has a more clearly defined and less ambiguous `old_string`.  \r\n  \r\n**Rationale**:  \r\n*   By anchoring the main insertion on a very stable, unique line *after* the insertion point and prepending the new code to it, you reduce the risk of `old_string` mismatches caused by subtle variations in the code *before* the insertion point.  \r\n*   Keeping ancillary edits separate allows them to succeed even if the main insertion point is complex, as they often target simpler, more reliable `old_string` patterns.  \r\n*   This approach leverages `MultiEdit`'s sequential application of changes effectively.  \r\n  \r\n**Example Scenario**: Adding new methods to a class and a call to one of these new methods elsewhere.  \r\n*   **Edit 1**: Insert the new methods. `old_string` is the class's closing brace `}`. `new_string` is `  \r\n    [new methods code]  \r\n    }`.  \r\n*   **Edit 2**: Insert the call to a new method. `old_string` is `// existing line before call`. `new_string` is `// existing line before call  \r\n    this.newMethodCall();`.  \r\n  \r\nThis method provides a balance between precise editing and handling larger code insertions reliably when direct `old_string` matches for the entire new block are problematic.  \r\n  \r\n## Handling Large Files for Incremental Refactoring  \r\n\r\nWhen refactoring large files incrementally rather than rewriting them completely:  \r\n\r\n1. **Initial Exploration and Planning**:  \r\n   * Begin with targeted searches using `rg` to locate specific patterns or sections within the file.  \r\n   * Use `Bash` commands like `rg \"pattern\" file` to find line numbers for specific areas of interest.  \r\n   * Create a clear mental model of the file structure before proceeding with edits.  \r\n\r\n2. **Chunked Reading for Large Files**:  \r\n   * For files too large to read at once, use multiple `Read` operations with different `offset` and `limit` parameters.  \r\n   * Read sequential chunks to build a complete understanding of the file.  \r\n   * Use `rg` to pinpoint key sections, then read just those sections with targeted `offset` parameters.  \r\n\r\n3. **Finding Key Implementation Sections**:  \r\n   * Use `Bash` commands with `rg -A N` (to show N lines after a match) or `rg -B N` (to show N lines before) to locate function or method implementations.  \r\n   * Example: `rg \"function findTagBoundaries\" -A 20 filename.js` to see the first 20 lines of a function.  \r\n\r\n4. **Pattern-Based Replacement Strategy**:  \r\n   * Identify common patterns that need to be replaced across the file.  \r\n   * Use the `Bash` tool with `sed` for quick previews of potential replacements.  \r\n   * Example: `sed -n \"s/oldPattern/newPattern/gp\" filename.js` to preview changes without making them.  \r\n\r\n5. **Sequential Selective Edits**:  \r\n   * Target specific sections or patterns one at a time rather than attempting a complete rewrite.  \r\n   * Focus on clearest/simplest cases first to establish a pattern of successful edits.  \r\n   * Use `Edit` for well-defined single changes within the file.  \r\n\r\n6. **Batch Similar Changes Together**:  \r\n   * Group similar types of changes (e.g., all references to a particular function or variable).  \r\n   * Use `rg` to preview the scope of batch changes: `rg \"pattern\" filename.js | wc -l`  \r\n   * For systematic changes across a file, consider using `sed` through the `Bash` tool: `sed -i \"s/oldPattern/newPattern/g\" filename.js`  \r\n\r\n7. **Incremental Verification**:  \r\n   * After each set of changes, verify the specific sections that were modified.  \r\n   * For critical components, read the surrounding context to ensure the changes integrate correctly.  \r\n   * Validate that each change maintains the file's structure and logic before proceeding to the next.  \r\n\r\n8. **Progress Tracking for Large Refactors**:  \r\n   * Use the `TodoWrite` tool to track which sections or patterns have been updated.  \r\n   * Create a checklist of all required changes and mark them off as they're completed.  \r\n   * Record any sections that require special attention or that couldn't be automatically refactored.  \r\n\r\n## Shell & CLI Tools\r\n\r\nClaude Code **MUST** leverage the comprehensive suite of installed command-line tools to augment built-in capabilities for maximum efficiency, precision, and flexibility.\r\n\r\n### Tool Selection Strategy\r\n\r\nFor operations where command-line tools provide superior performance or precision compared to file system abstractions, Claude Code will prefer the `Bash` tool. This includes bulk text processing, data transformation, system introspection, build operations, and validation tasks.\r\n\r\n### Core Text Processing and Data Parsing\r\n\r\n1.  **`ripgrep (rg)`**: For all codebase searches, Claude Code will use `rg` instead of `grep`. It respects `.gitignore` by default and provides faster, more readable output.\r\n    *   Locate definitions: `rg \"function\\s+\\w+\" --line-number --no-ignore`\r\n    *   Contextual search: `rg \"class\\s+User\" -A 20 -B 5` (20 lines after, 5 lines before match)\r\n    *   Find TODOs: `rg \"TODO|FIXME\" --line-number | awk -F: '{print $1}' | sort | uniq -c`\r\n\r\n2.  **`jq`/`yq`**: For processing structured data files (JSON/YAML) and API responses.\r\n    *   Extract values: `yq eval '.dependencies.react.version' package.json`\r\n    *   Chain with curl: `curl -s https://api.github.com/repos/owner/repo | jq '.stargazers_count'`\r\n    *   Update YAML: `yq eval '.services.app.image = \"new:tag\"' -i docker-compose.yml`\r\n\r\n3.  **`sed`**: For batch replacements across files where `MultiEdit` would be inefficient.\r\n    *   **Always preview first**: `sed -n 's/oldPattern/newPattern/gp' filename.js`\r\n    *   **Apply changes**: `sed -i 's/oldPattern/newPattern/g' filename.js`\r\n    *   Target specific line ranges: `sed -i '100,200s/foo/bar/g' large_file.cpp`\r\n\r\n4.  **`awk`**: For columnar data processing and pattern-based extraction.\r\n    *   Parse logs: `awk '$4 > 100 {print $1, $5}' metrics.log`\r\n    *   Field extraction: `awk '{print $2}' file.txt | sort | uniq -c`\r\n\r\n### Development and Build Toolchain\r\n\r\n1.  **`cmake`/`ninja`**: For C/C++ projects, Claude Code will use these directly rather than abstracted build commands.\r\n    *   Configure: `cmake -B build -G Ninja -DCMAKE_BUILD_TYPE=Release -DCMAKE_EXPORT_COMPILE_COMMANDS=ON`\r\n    *   Build: `ninja -C build -j$(nproc)`\r\n    *   Clean rebuild: `rm -rf build && cmake -B build -G Ninja && ninja -C build`\r\n\r\n2.  **`llvm-config`**: To obtain correct LLVM compilation flags dynamically.\r\n    *   **Always use**: `llvm-config --cxxflags --ldflags --libs core`\r\n    *   Never hardcode LLVM paths or versions.\r\n\r\n3.  **`pkg-config`**: For obtaining library compiler/linker flags.\r\n    *   Standard pattern: `pkg-config --cflags --libs opencv4`\r\n    *   Check availability: `pkg-config --exists libname && echo \"Found\" || echo \"Missing\"`\r\n\r\n4.  **`cargo`**: For Rust operations, prefer direct cargo commands.\r\n    *   Check: `cargo check --workspace --all-targets`\r\n    *   Build: `cargo build --release`\r\n    *   Test: `cargo test --workspace`\r\n\r\n### Language Compiler Direct Usage\r\n\r\n1.  **`go`**: Use `go build`, `go test`, `go mod tidy` for Go projects.\r\n2.  **`gcc`/`g++`**: For quick C/C++ compilation tests or single-file builds: `g++ -std=c++20 -Wall -Wextra file.cpp -o file`\r\n3.  **`clang`/`clang++`**: Prefer for modern C++ features and better diagnostics.\r\n4.  **`rustc`/`rustfmt`**: Use for individual file compilation or formatting verification.\r\n\r\n### Network and System Operations\r\n\r\n1.  **`docker`**: For container and image management.\r\n    *   Build: `docker build -t app:latest .`\r\n    *   Compose operations: `docker compose up -d --build`\r\n    *   Inspect metadata: `docker inspect container_name | jq '.[0].State.Status'`\r\n    *   Clean up: `docker system prune -f`\r\n\r\n2.  **`curl`**: For HTTP requests and file downloads.\r\n    *   API testing: `curl -X POST -H \"Content-Type: application/json\" -d '{\"key\":\"value\"}' https://api.example.com`\r\n    *   Download with redirect: `curl -L -o archive.tar.gz https://example.com/file.tar.gz`\r\n    *   Header inspection: `curl -I https://example.com`\r\n\r\n3.  **`sqlite3`**: For database inspection and quick queries.\r\n    *   Execute: `sqlite3 database.db \"SELECT COUNT(*) FROM migrations;\"`\r\n    *   Export: `sqlite3 database.db \".mode csv\" \".output data.csv\" \"SELECT * FROM table;\"`\r\n\r\n4.  **`netcat (nc)`**: For network connectivity testing.\r\n    *   Port test: `nc -zv localhost 3000`\r\n    *   Service check: `echo \"test\" | nc -w 2 localhost 8080`\r\n\r\n### File and System Introspection\r\n\r\n1.  **`lsof`**: To identify processes using files or ports.\r\n    *   Port conflict resolution: `lsof -i :3000`\r\n    *   Open files by process: `lsof -p $(pgrep -f process_name)`\r\n\r\n2.  **`tree`**: To visualize directory structure.\r\n    *   JSON output: `tree -J -L 2 | jq '.[0].contents'`\r\n\r\n3.  **`fd-find (fdfind)`**: To locate files by pattern.\r\n    *   Find source files: `fd -e cpp -e hpp src/`\r\n    *   Find directories: `fd -t d -L 2`\r\n\r\n4.  **`openssl`**: For certificate and cryptographic operations.\r\n    *   Generate self-signed: `openssl req -x509 -newkey rsa:4096 -keyout key.pem -out cert.pem -days 365 -nodes`\r\n\r\n### Effective Usage Patterns\r\n\r\n1.  **Preview Before Apply**: Claude Code will always preview destructive operations before execution.\r\n    *   Use `--dry-run`, `-n` flags, or redirect to stdout first to verify behavior.\r\n\r\n2.  **Tool Composition**: Chain tools for complex operations.\r\n    *   Process grep results: `rg \"pattern\" --line-number | awk -F: '{print $1}' | sort | uniq -c`\r\n\r\n3.  **Output Filtering**: Narrow results before processing with Claude's tools.\r\n    *   Filter containers: `docker ps --format json | jq '. | select(.State == \"running\")'`\r\n\r\n4.  **Batch Processing**: Use loops for repetitive operations.\r\n    *   Clean temporary files: `for file in $(fd -e .tmp); do rm \"$file\"; done`\r\n\r\n5.  **Dynamic Values**: Use command substitution for dynamic data.\r\n    *   Parallel builds: `ninja -C build -j$(nproc)`\r\n\r\n### Package Runtime Tools (npx/uvx)\r\n\r\nFor isolated execution of ecosystem tools without global installation:\r\n\r\n1.  **`npx` (Node.js)**:\r\n    *   Run linters: `npx eslint . --fix`\r\n    *   Execute scaffolding: `npx create-vite@latest my-project -- --template react`\r\n    *   One-off tools: `npx http-server -p 8080`\r\n    *   Version pinning: `npx playwright@1.40.0 test`\r\n\r\n2.  **`uvx` (Python)**:\r\n    *   Format code: `uvx ruff format .`\r\n    *   Type checking: `uvx --with mypy-extensions mypy src/`\r\n    *   Run scripts with deps: `uvx --with requests --with pydantic python script.py`\r\n    *   Tool installation: `uvx --reinstall tool-name`\r\n\r\n## Leveraging Subagents and Skills\r\n\r\nClaude Code **MUST** proactively leverage installed subagents and skills as primary mechanisms for specialized tasks, ensuring maximum efficiency and consistent application of expertise. Direct implementation should be considered secondary to delegation when a relevant subagent or skill is available.\r\n\r\n### Delegation Priority Rule\r\n\r\nWhen a task aligns with any subagent or skill description, Claude Code will delegate first and only implement directly as a fallback.\r\n\r\n**Verification After Delegation:**\r\n   - Confirm which subagent(s)/skill(s) were invoked\r\n   - Summarize the specialized expertise applied\r\n   - Explain how outputs integrate with the task\r\n\r\n**Failure Handling:**\r\n\r\nIf delegation fails:\r\n   1. Analyze the failure reason\r\n   2. Attempt alternative subagents with overlapping capabilities\r\n   3. Document the limitation before direct implementation\r\n\r\n### Subagent Utilization Protocol\r\n\r\n**Automatic Delegation Triggers:**\r\n\r\nClaude Code will automatically invoke appropriate subagents when detecting:\r\n   - **Architecture & Design Requests**: Any mention of API design, system architecture, or pattern selection \u2192 `backend-architect`, `graphql-architect`, `architecture-patterns`\r\n   - **Security & Performance**: Security audits, vulnerability scanning, or performance optimization \u2192 `security-auditor`, `performance-engineer`\r\n   - **Debugging & Diagnostics**: Error investigation or root cause analysis \u2192 `debugger`, `error-detective`\r\n   - **Testing Requirements**: Test generation, test coverage analysis, or testing strategy \u2192 `test-automator`, `tdd-orchestrator`\r\n   - **Technology-Specific Tasks**: Language/framework-specific implementations (FastAPI, Django, Rust, Go) \u2192 `fastapi-pro`, `django-pro`, `rust-pro`, `golang-pro`\r\n   - **Deployment & Operations**: Deployment, CI/CD setup, or infrastructure \u2192 `deployment-engineer`, `devops-troubleshooter`\r\n\r\n**Explicit Invocation Patterns:**\r\n\r\nClaude Code will recognize and act on explicit natural language cues:\r\n   - \"Have the code-reviewer subagent analyze this PR\"\r\n   - \"Use the debugger to investigate this stack trace\"\r\n   - \"Get the backend-architect to design this authentication API\"\r\n   - \"Run the security-auditor on this module\"\r\n\r\n### Prompt for Task Delegation\r\n\r\nEffective delegation requires intentionally structured prompts that clearly communicate task boundaries, success criteria, and integration points. Use these patterns to maximize subagent effectiveness:\r\n\r\n**1. Explicit Context Transfer**\r\n\r\nWhen delegating, always provide:\r\n   - **Current state**: What has been done so far\r\n   - **Specific goal**: What needs to be accomplished\r\n   - **Constraints**: Non-negotiable requirements (performance, security, style)\r\n   - **Integration points**: How results connect to the broader system\r\n\r\n**2. Actionable Task Framing**\r\n\r\nEffective framing turns vague requests into clear, executable directives:\r\n1. **Code Review Requests**\r\n   - **Ineffective pattern**: Generic requests like \"Review this code\" without scope or focus areas\r\n   - **Effective transformation**: Specify analysis scope, target areas, and required output format\r\n   - **Key elements**: Explicit scope (security + API design), quantified output (3+ recommendations), structured format (severity levels)\r\n\r\n2. **Bug Investigation Delegation**\r\n   - **Ineffective pattern**: \"Fix this bug\" without reproduction context or process definition\r\n   - **Effective transformation**: Provide reproduction data, define root cause analysis steps, and require verification procedures\r\n   - **Key elements**: Multi-step process with tool specifications, quantitative alternatives (2+ solutions), safety-first approach\r\n\r\n3. **Test Generation Tasks**\r\n   - **Ineffective pattern**: \"Write tests\" without coverage requirements or framework context\r\n   - **Effective transformation**: Define coverage targets, testing frameworks, and specific edge cases to validate\r\n   - **Key elements**: Specific coverage targets (happy path + edge cases), framework constraints (pytest fixtures), technical requirements (async patterns)\r\n\r\n4. **Performance Optimization**\r\n   - **Ineffective pattern**: Ambiguous goals like \"Make it faster\" without measurement criteria\r\n   - **Effective transformation**: Specify profiling tools, validation methodology, and measurable success targets\r\n   - **Key elements**: Named profiling tool (cProfile), quantified validation (3+ iterations), specific performance target (>20% improvement)\r\n\r\n### Skill Activation Strategy\r\n\r\nWhen requirements match installed skill descriptions, Claude Code automatically activates the relevant skills without explicit prompting.\r\n\r\n**Activation Examples:**\r\n   - Python async code \u2192 `async-python-patterns` + `python-testing-patterns`\r\n   - Database queries \u2192 `sql-optimization-patterns`\r\n   - API implementation \u2192 `api-design-principles` + `auth-implementation-patterns`\r\n   - Git operations \u2192 `git-advanced-workflows`\r\n   - Error handling \u2192 `error-handling-patterns`\r\n   - Code review \u2192 `code-review-excellence`\r\n\r\nWhen activating skills, Claude Code will acknowledge them: \"Activating `[skill-name]` for [specific aspect].\"\r\n\r\n## General Interaction  \r\n  \r\n* Prefer responding in English unless the user explicitly requests Chinese.\r\n* Claude Code will directly apply proposed changes and modifications using the available tools, rather than describing them and asking you to implement them manually. This ensures a more efficient and direct workflow.  \r\n\n\n      IMPORTANT: this context may or may not be relevant to your tasks. You should not respond to this context unless it is highly relevant to your task.\n</system-reminder>\n"
        },
        {
          "type": "text",
          "text": "This session is being continued from a previous conversation that ran out of context. The conversation is summarized below:\nAnalysis:\nLet me chronologically analyze this conversation:\n\n1. **Initial User Request**: The user asked me to execute the High Priority consolidation plan from two documentation files (@_consolidation/SUBAGENTS_README.md and @_consolidation/SUBAGENTS_CATEGORIZATION.md), and delete old files after completion.\n\n2. **My Initial Approach**: \n   - I attempted to use TodoWrite to create a task list but encountered an API Error 400\n   - The user said \"continue\" so I proceeded by reading the two consolidation documentation files\n   - I then created a proper todo list and began systematically working through the high-priority consolidations\n\n3. **Consolidation Work Completed**:\n   \n   **A. SEO & Content Marketing (10 \u2192 1 agent)**:\n   - Read all 10 SEO agent files: seo-content-planner.md, seo-content-writer.md, seo-content-refresher.md, seo-content-auditor.md, seo-snippet-hunter.md, seo-meta-optimizer.md, seo-structure-architect.md, seo-keyword-strategist.md, seo-authority-builder.md, seo-cannibalization-detector.md\n   - Created comprehensive consolidated file: seo-expert.md\n   - This agent combines all SEO capabilities: content strategy, writing, optimization, auditing, freshness, technical SEO, metadata, snippets, keywords, E-E-A-T, and cannibalization detection\n   \n   **B. Architecture & Design (8 \u2192 3 agents)**:\n   - Read architecture agents: backend-architect.md, graphql-architect.md, database-architect.md, architect-review.md, docs-architect.md, hybrid-cloud-architect.md, kubernetes-architect.md, cloud-architect.md\n   - Created three consolidated files:\n     - **api-architect.md**: Consolidated backend-architect + graphql-architect (API-focused architecture)\n     - **system-architect.md**: Consolidated architect-review + docs-architect (system design & documentation)\n     - **cloud-architect.md**: Consolidated cloud-architect + hybrid-cloud-architect + kubernetes-architect (cloud infrastructure)\n   - Note: database-architect was saved for the Database Operations consolidation\n   \n   **C. Database Operations (3 \u2192 1 agent)**:\n   - Read database agents: database-architect.md (already read earlier), database-admin.md, database-optimizer.md\n   - Created comprehensive consolidated file: database-expert.md\n   - This agent combines architecture, administration, and optimization capabilities\n\n4. **Progress Tracking**: I consistently updated the todo list after each major consolidation to track progress.\n\n5. **Current Status**: \n   - Completed 3 of 6 high-priority consolidations (29 agents \u2192 5 agents so far)\n   - Remaining: Debugging (3\u21921), Security Coding (3\u21921), Shell Scripting (2\u21921)\n   - Still need to: Delete old files, Update documentation\n\n6. **User Messages**:\n   - Initial request to start consolidation and delete old files\n   - \"continue\" after the API error\n\n7. **Errors Encountered**:\n   - API Error 400 on first TodoWrite attempt - I simply continued with the work and successfully used TodoWrite on the second attempt\n\n8. **Technical Approach**:\n   - Each consolidation preserves ALL unique functionality from source agents\n   - Zero information loss philosophy\n   - Comprehensive capability coverage\n   - Clear behavioral traits and workflow positioning\n   - Detailed examples and output formats\n\nSummary:\n## 1. Primary Request and Intent:\nThe user requested execution of the High Priority consolidation plan for sub-agents, specifically:\n- Consolidate 29 high-priority sub-agents into 8 consolidated agents\n- Delete old files after completion\n- Update documentation and indexes\n- Focus on categories: SEO & Content Marketing (10\u21921), Architecture & Design (8\u21923), Database Operations (3\u21921), Debugging & Troubleshooting (3\u21921), Security Coding (3\u21921), and Shell Scripting (2\u21921)\n\n## 2. Key Technical Concepts:\n- **Sub-agent consolidation**: Merging multiple specialized agents into comprehensive experts\n- **Zero information loss**: Preserving all unique functionality from source agents\n- **SEO optimization**: Content strategy, E-E-A-T signals, featured snippets, keyword optimization, meta tags\n- **API architecture**: REST, GraphQL, gRPC, microservices, event-driven architecture\n- **System architecture**: Clean architecture, DDD, SOLID principles, distributed systems\n- **Cloud architecture**: Multi-cloud (AWS/Azure/GCP), Kubernetes, GitOps, hybrid cloud, OpenStack\n- **Database expertise**: Technology selection, schema design, query optimization, operations, caching\n- **Infrastructure as Code**: Terraform, CloudFormation, Helm, Kustomize\n- **GitOps**: ArgoCD, Flux, declarative infrastructure\n- **Service mesh**: Istio, Linkerd, Cilium\n\n## 3. Files and Code Sections:\n\n### Created Files:\n\n**seo-expert.md**\n- **Purpose**: Consolidated all 10 SEO agents into one comprehensive expert\n- **Key capabilities**: Content strategy & planning, content creation & writing, optimization & auditing, freshness & maintenance, technical SEO & structure, metadata optimization, featured snippet optimization, keyword strategy & semantics, E-E-A-T & authority building, cannibalization detection & resolution\n- **Important snippet**:\n```yaml\n---\nname: seo-expert\ndescription: Comprehensive SEO specialist covering content strategy, writing, optimization, technical SEO, E-E-A-T, and performance analysis. Handles all aspects of search engine optimization from planning to execution. Use PROACTIVELY for any SEO-related tasks.\nmodel: sonnet\n---\n```\n\n**api-architect.md**\n- **Purpose**: Consolidated backend-architect + graphql-architect for API-focused architecture\n- **Key capabilities**: RESTful API design, GraphQL architecture (federation, performance, caching), gRPC services, microservices architecture, event-driven architecture, authentication & authorization, security patterns, resilience & fault tolerance, observability & monitoring\n- **Important snippet**:\n```yaml\n---\nname: api-architect\ndescription: Expert API and backend architect specializing in scalable API design (REST/GraphQL/gRPC), microservices architecture, distributed systems, and event-driven architectures. Masters service boundaries, inter-service communication, resilience patterns, GraphQL federation, and modern backend frameworks. Use PROACTIVELY for API design, backend architecture, or microservices planning.\nmodel: sonnet\n---\n```\n\n**system-architect.md**\n- **Purpose**: Consolidated architect-review + docs-architect for system design & documentation\n- **Key capabilities**: Modern architecture patterns (clean architecture, microservices, event-driven, DDD), distributed systems design, SOLID principles & design patterns, cloud-native architecture, security architecture, performance & scalability, architecture documentation (C4 model, ADRs, comprehensive technical documentation)\n- **Important snippet**:\n```yaml\n---\nname: system-architect\ndescription: Master software architect specializing in modern architecture patterns, clean architecture, microservices, event-driven systems, DDD, and comprehensive technical documentation. Reviews system designs for architectural integrity, scalability, and maintainability. Creates long-form technical documentation from codebases. Use PROACTIVELY for architectural decisions, system design reviews, or technical documentation.\nmodel: sonnet\n---\n```\n\n**cloud-architect.md** (replaced existing)\n- **Purpose**: Consolidated cloud-architect + hybrid-cloud-architect + kubernetes-architect\n- **Key capabilities**: Multi-cloud platforms (AWS/Azure/GCP), private & hybrid cloud (OpenStack, VMware), Kubernetes & container orchestration, GitOps & progressive delivery, cloud-native security, service mesh & networking, Infrastructure as Code mastery, cost optimization & FinOps, workload placement, disaster recovery\n- **Important snippet**:\n```yaml\n---\nname: cloud-architect\ndescription: Expert cloud architect specializing in AWS/Azure/GCP multi-cloud infrastructure, hybrid cloud solutions, Kubernetes/container orchestration, advanced IaC (Terraform/CDK), GitOps, FinOps cost optimization, and modern cloud-native patterns. Masters serverless, microservices, security, compliance, disaster recovery, and platform engineering. Use PROACTIVELY for cloud architecture, Kubernetes design, hybrid cloud strategy, cost optimization, or migration planning.\nmodel: sonnet\n---\n```\n\n**database-expert.md**\n- **Purpose**: Consolidated database-architect + database-admin + database-optimizer\n- **Key capabilities**: Database architecture & design (technology selection, data modeling, schema design), cloud database platforms (AWS/Azure/GCP), advanced indexing & query optimization, caching architecture, scalability & performance, database operations & administration, migration & schema evolution, transaction design & consistency\n- **Important snippet**:\n```yaml\n---\nname: database-expert\ndescription: Comprehensive database expert specializing in data layer architecture, database administration, and performance optimization. Masters technology selection, schema design, cloud databases (AWS/Azure/GCP), query optimization, high availability, disaster recovery, and cost optimization. Handles greenfield design, operations, and performance tuning. Use PROACTIVELY for database architecture, operations, optimization, or any database-related tasks.\nmodel: sonnet\n---\n```\n\n### Read Files:\n- **SUBAGENTS_README.md**: Project overview, consolidation strategy, 88 agents \u2192 ~37 target\n- **SUBAGENTS_CATEGORIZATION.md**: Complete inventory of all 88 sub-agents organized into 21 categories\n- All 10 SEO agent files (seo-content-planner, seo-content-writer, etc.)\n- All 8 architecture agent files (backend-architect, graphql-architect, etc.)\n- All 3 database agent files (database-architect, database-admin, database-optimizer)\n\n## 4. Errors and Fixes:\n- **API Error 400 on first TodoWrite attempt**: \n  - Error: `{\"error\":{\"type\":\"bad_response_status_code\",\"message\":\"Improperly formed request. (request id: 20251112163536319878512Haq4pAQL)\"}}`\n  - Fix: User said \"continue\", so I proceeded with reading the documentation files and successfully used TodoWrite on the second attempt with proper JSON formatting\n  - No user feedback on the error itself\n\n## 5. Problem Solving:\n- **Consolidation Strategy**: Successfully merged agents by identifying overlapping capabilities and organizing them into comprehensive experts with clear capability sections\n- **Zero Information Loss**: Ensured all unique functionality from source agents was preserved in consolidated versions\n- **Workflow Positioning**: Maintained clear distinctions between consolidated agents (e.g., api-architect works after database-expert, system-architect focuses on patterns while cloud-architect focuses on infrastructure)\n- **File Management**: Created new consolidated files, replaced existing cloud-architect.md with consolidated version using `mv` command\n\n## 6. All User Messages:\n1. \"@_consolidation/SUBAGENTS_README.md @_consolidation/SUBAGENTS_CATEGORIZATION.md start High Priority for Consolidation plan, and delete the old files after completion.\"\n2. \"continue\"\n3. \"Your task is to create a detailed summary of the conversation so far...\" (current message requesting summary)\n\n## 7. Pending Tasks:\n- Consolidate Debugging & Troubleshooting (3 \u2192 1 agent): debug-expert\n- Consolidate Security Coding (3 \u2192 1 agent): security-coder-expert\n- Consolidate Shell Scripting (2 \u2192 1 agent): shell-scripting-expert\n- Delete old consolidated agent files (10 SEO files, 5 architecture files that were consolidated, 2 database files)\n- Update documentation and indexes\n\n## 8. Current Work:\nImmediately before the summary request, I had just completed the Database Operations consolidation:\n- Created **database-expert.md** consolidating database-architect, database-admin, and database-optimizer\n- Updated the todo list to mark Database Operations as completed\n- Provided a progress summary showing:\n  - \u2705 Completed: SEO (10\u21921), Architecture (8\u21923), Database (3\u21921)\n  - \ud83d\udd04 Remaining: Debugging (3\u21921), Security Coding (3\u21921), Shell Scripting (2\u21921), Delete old files, Update documentation\n- Asked the user: \"Would you like me to proceed with the Debugging & Troubleshooting consolidation next?\"\n\nThe todo list status at the time of summary request:\n```\n1. [completed] Consolidate SEO & Content Marketing (10 \u2192 1 agent): seo-expert\n2. [completed] Consolidate Architecture & Design (8 \u2192 3 agents): system-architect, cloud-architect, api-architect\n3. [completed] Consolidate Database Operations (3 \u2192 1 agent): database-expert\n4. [in_progress] Consolidate Debugging & Troubleshooting (3 \u2192 1 agent): debug-expert\n5. [pending] Consolidate Security Coding (3 \u2192 1 agent): security-coder-expert\n6. [pending] Consolidate Shell Scripting (2 \u2192 1 agent): shell-scripting-expert\n7. [pending] Delete old consolidated agent files\n8. [pending] Update documentation and indexes\n```\n\n## 9. Optional Next Step:\nContinue with the Debugging & Troubleshooting consolidation (3 \u2192 1 agent: debug-expert) as this is the next high-priority task in the consolidation plan.\n\n**Direct quote from conversation showing where I left off**:\n> \"### \ud83d\udd04 Remaining High-Priority Tasks:\n> 4. Debugging & Troubleshooting (3 \u2192 1)\n> 5. Security Coding (3 \u2192 1)\n> 6. Shell Scripting (2 \u2192 1)\n> 7. Delete old consolidated files\n> 8. Update documentation\n> \n> Let me continue with the remaining consolidations. Would you like me to proceed with the Debugging & Troubleshooting consolidation next?\"\n\nThe next step would be to:\n1. Find and read the 3 debugging agent files (debugger.md, error-detective.md, devops-troubleshooter.md)\n2. Create consolidated debug-expert.md\n3. Continue with remaining consolidations (Security Coding, Shell Scripting)\n4. Delete old files\n5. Update documentation."
        }
      ]
    },
    {
      "role": "assistant",
      "content": [
        {
          "id": "tooluse_JZU_zQLIS7usPpEELf2wlg",
          "input": {
            "todos": [
              {
                "content": "Consolidate SEO & Content Marketing (10 \u2192 1 agent): seo-expert",
                "status": "completed",
                "activeForm": "Consolidate SEO & Content Marketing"
              },
              {
                "status": "completed",
                "activeForm": "Consolidate Architecture & Design",
                "content": "Consolidate Architecture & Design (8 \u2192 3 agents): system-architect, cloud-architect, api-architect"
              },
              {
                "content": "Consolidate Database Operations (3 \u2192 1 agent): database-expert",
                "status": "completed",
                "activeForm": "Consolidate Database Operations"
              },
              {
                "status": "in_progress",
                "activeForm": "Consolidate Debugging & Troubleshooting",
                "content": "Consolidate Debugging & Troubleshooting (3 \u2192 1 agent): debug-expert"
              },
              {
                "status": "pending",
                "activeForm": "Consolidate Security Coding",
                "content": "Consolidate Security Coding (3 \u2192 1 agent): security-coder-expert"
              },
              {
                "content": "Consolidate Shell Scripting (2 \u2192 1 agent): shell-scripting-expert",
                "status": "pending",
                "activeForm": "Consolidate Shell Scripting"
              },
              {
                "activeForm": "Delete old files",
                "content": "Delete old consolidated agent files",
                "status": "pending"
              },
              {
                "content": "Update documentation and indexes",
                "status": "pending",
                "activeForm": "Update documentation"
              }
            ]
          },
          "name": "TodoWrite",
          "type": "tool_use"
        },
        {
          "text": "I can see from the summary that I was in the middle of executing the High Priority consolidation plan. I had completed 3 of 6 consolidations (SEO, Architecture, and Database Operations) and was about to proceed with Debugging & Troubleshooting.\n\nLet me continue with the remaining high-priority consolidations.",
          "type": "text",
          "cache_control": {
            "type": "ephemeral"
          }
        }
      ]
    },
    {
      "content": [
        {
          "content": "Todos have been modified successfully. Ensure that you continue to use the todo list to track your progress. Please proceed with the current tasks if applicable",
          "cache_control": {
            "type": "ephemeral"
          },
          "tool_use_id": "tooluse_JZU_zQLIS7usPpEELf2wlg",
          "type": "tool_result"
        }
      ],
      "role": "user"
    }
  ],
  "max_tokens": 16384,
  "stream": true,
  "tools": [
    {
      "description": "Launch a new agent to handle complex, multi-step tasks autonomously. \n\nThe Task tool launches specialized agents (subprocesses) that autonomously handle complex tasks. Each agent type has specific capabilities and tools available to it.\n\nAvailable agent types and the tools they have access to:\n- general-purpose: General-purpose agent for researching complex questions, searching for code, and executing multi-step tasks. When you are searching for a keyword or file and are not confident that you will find the right match in the first few tries use this agent to perform the search for you. (Tools: *)\n- statusline-setup: Use this agent to configure the user's Claude Code status line setting. (Tools: Read, Edit)\n- Explore: Fast agent specialized for exploring codebases. Use this when you need to quickly find files by patterns (eg. \"src/components/**/*.tsx\"), search code for keywords (eg. \"API endpoints\"), or answer questions about the codebase (eg. \"how do API endpoints work?\"). When calling this agent, specify the desired thoroughness level: \"quick\" for basic searches, \"medium\" for moderate exploration, or \"very thorough\" for comprehensive analysis across multiple locations and naming conventions. (Tools: All tools)\n- Plan: Fast agent specialized for exploring codebases. Use this when you need to quickly find files by patterns (eg. \"src/components/**/*.tsx\"), search code for keywords (eg. \"API endpoints\"), or answer questions about the codebase (eg. \"how do API endpoints work?\"). When calling this agent, specify the desired thoroughness level: \"quick\" for basic searches, \"medium\" for moderate exploration, or \"very thorough\" for comprehensive analysis across multiple locations and naming conventions. (Tools: All tools)\n- posix-shell-pro: Expert in strict POSIX sh scripting for maximum portability across Unix-like systems. Specializes in shell scripts that run on any POSIX-compliant shell (dash, ash, sh, bash --posix). (Tools: All tools)\n- security-auditor: Expert security auditor specializing in DevSecOps, comprehensive cybersecurity, and compliance frameworks. Masters vulnerability assessment, threat modeling, secure authentication (OAuth2/OIDC), OWASP standards, cloud security, and security automation. Handles DevSecOps integration, compliance (GDPR/HIPAA/SOC2), and incident response. Use PROACTIVELY for security audits, DevSecOps, or compliance implementation. (Tools: All tools)\n- seo-content-auditor: Analyzes provided content for quality, E-E-A-T signals, and SEO best practices. Scores content and provides improvement recommendations based on established guidelines. Use PROACTIVELY for content review. (Tools: All tools)\n- ml-engineer: Build production ML systems with PyTorch 2.x, TensorFlow, and modern ML frameworks. Implements model serving, feature engineering, A/B testing, and monitoring. Use PROACTIVELY for ML model deployment, inference optimization, or production ML infrastructure. (Tools: All tools)\n- content-marketer: Elite content marketing strategist specializing in AI-powered content creation, omnichannel distribution, SEO optimization, and data-driven performance marketing. Masters modern content tools, social media automation, and conversion optimization with 2024/2025 best practices. Use PROACTIVELY for comprehensive content marketing. (Tools: All tools)\n- api-architect: Expert API and backend architect specializing in scalable API design (REST/GraphQL/gRPC), microservices architecture, distributed systems, and event-driven architectures. Masters service boundaries, inter-service communication, resilience patterns, GraphQL federation, and modern backend frameworks. Use PROACTIVELY for API design, backend architecture, or microservices planning. (Tools: All tools)\n- backend-architect: Expert backend architect specializing in scalable API design, microservices architecture, and distributed systems. Masters REST/GraphQL/gRPC APIs, event-driven architectures, service mesh patterns, and modern backend frameworks. Handles service boundary definition, inter-service communication, resilience patterns, and observability. Use PROACTIVELY when creating new backend services or APIs. (Tools: All tools)\n- deployment-engineer: Expert deployment engineer specializing in modern CI/CD pipelines, GitOps workflows, and advanced deployment automation. Masters GitHub Actions, ArgoCD/Flux, progressive delivery, container security, and platform engineering. Handles zero-downtime deployments, security scanning, and developer experience optimization. Use PROACTIVELY for CI/CD design, GitOps implementation, or deployment automation. (Tools: All tools)\n- reference-builder: Creates exhaustive technical references and API documentation. Generates comprehensive parameter listings, configuration guides, and searchable reference materials. Use PROACTIVELY for API docs, configuration references, or complete technical specifications. (Tools: All tools)\n- tutorial-engineer: Creates step-by-step tutorials and educational content from code. Transforms complex concepts into progressive learning experiences with hands-on examples. Use PROACTIVELY for onboarding guides, feature tutorials, or concept explanations. (Tools: All tools)\n- fastapi-pro: Build high-performance async APIs with FastAPI, SQLAlchemy 2.0, and Pydantic V2. Master microservices, WebSockets, and modern Python async patterns. Use PROACTIVELY for FastAPI development, async optimization, or API architecture. (Tools: All tools)\n- sql-pro: Master modern SQL with cloud-native databases, OLTP/OLAP optimization, and advanced query techniques. Expert in performance tuning, data modeling, and hybrid analytical systems. Use PROACTIVELY for database optimization or complex analysis. (Tools: All tools)\n- seo-cannibalization-detector: Analyzes multiple provided pages to identify keyword overlap and potential cannibalization issues. Suggests differentiation strategies. Use PROACTIVELY when reviewing similar content. (Tools: All tools)\n- ios-developer: Develop native iOS applications with Swift/SwiftUI. Masters iOS 18, SwiftUI, UIKit integration, Core Data, networking, and App Store optimization. Use PROACTIVELY for iOS-specific features, App Store optimization, or native iOS development. (Tools: All tools)\n- graphql-architect: Master modern GraphQL with federation, performance optimization, and enterprise security. Build scalable schemas, implement advanced caching, and design real-time systems. Use PROACTIVELY for GraphQL architecture or performance optimization. (Tools: All tools)\n- database-admin: Expert database administrator specializing in modern cloud databases, automation, and reliability engineering. Masters AWS/Azure/GCP database services, Infrastructure as Code, high availability, disaster recovery, performance optimization, and compliance. Handles multi-cloud strategies, container databases, and cost optimization. Use PROACTIVELY for database architecture, operations, or reliability engineering. (Tools: All tools)\n- debugger: Debugging specialist for errors, test failures, and unexpected behavior. Use proactively when encountering any issues. (Tools: All tools)\n- observability-engineer: Build production-ready monitoring, logging, and tracing systems. Implements comprehensive observability strategies, SLI/SLO management, and incident response workflows. Use PROACTIVELY for monitoring infrastructure, performance optimization, or production reliability. (Tools: All tools)\n- legal-advisor: Draft privacy policies, terms of service, disclaimers, and legal notices. Creates GDPR-compliant texts, cookie policies, and data processing agreements. Use PROACTIVELY for legal documentation, compliance texts, or regulatory requirements. (Tools: All tools)\n- seo-snippet-hunter: Formats content to be eligible for featured snippets and SERP features. Creates snippet-optimized content blocks based on best practices. Use PROACTIVELY for question-based content. (Tools: All tools)\n- php-pro: Write idiomatic PHP code with generators, iterators, SPL data structures, and modern OOP features. Use PROACTIVELY for high-performance PHP applications. (Tools: All tools)\n- golang-pro: Master Go 1.21+ with modern patterns, advanced concurrency, performance optimization, and production-ready microservices. Expert in the latest Go ecosystem including generics, workspaces, and cutting-edge frameworks. Use PROACTIVELY for Go development, architecture design, or performance optimization. (Tools: All tools)\n- rust-pro: Master Rust 1.75+ with modern async patterns, advanced type system features, and production-ready systems programming. Expert in the latest Rust ecosystem including Tokio, axum, and cutting-edge crates. Use PROACTIVELY for Rust development, performance optimization, or systems programming. (Tools: All tools)\n- frontend-security-coder: Expert in secure frontend coding practices specializing in XSS prevention, output sanitization, and client-side security patterns. Use PROACTIVELY for frontend security implementations or client-side security code reviews. (Tools: All tools)\n- scala-pro: Master enterprise-grade Scala development with functional programming, distributed systems, and big data processing. Expert in Apache Pekko, Akka, Spark, ZIO/Cats Effect, and reactive architectures. Use PROACTIVELY for Scala system design, performance optimization, or enterprise integration. (Tools: All tools)\n- arm-cortex-expert: > (Tools: [])\n- ui-visual-validator: Rigorous visual validation expert specializing in UI testing, design system compliance, and accessibility verification. Masters screenshot analysis, visual regression testing, and component validation. Use PROACTIVELY to verify UI modifications have achieved their intended goals through comprehensive visual analysis. (Tools: All tools)\n- error-detective: Search logs and codebases for error patterns, stack traces, and anomalies. Correlates errors across systems and identifies root causes. Use PROACTIVELY when debugging issues, analyzing logs, or investigating production errors. (Tools: All tools)\n- mobile-developer: Develop React Native, Flutter, or native mobile apps with modern architecture patterns. Masters cross-platform development, native integrations, offline sync, and app store optimization. Use PROACTIVELY for mobile features, cross-platform code, or app optimization. (Tools: All tools)\n- cloud-architect: Expert cloud architect specializing in AWS/Azure/GCP multi-cloud infrastructure, hybrid cloud solutions, Kubernetes/container orchestration, advanced IaC (Terraform/CDK), GitOps, FinOps cost optimization, and modern cloud-native patterns. Masters serverless, microservices, security, compliance, disaster recovery, and platform engineering. Use PROACTIVELY for cloud architecture, Kubernetes design, hybrid cloud strategy, cost optimization, or migration planning. (Tools: All tools)\n- database-expert: Comprehensive database expert specializing in data layer architecture, database administration, and performance optimization. Masters technology selection, schema design, cloud databases (AWS/Azure/GCP), query optimization, high availability, disaster recovery, and cost optimization. Handles greenfield design, operations, and performance tuning. Use PROACTIVELY for database architecture, operations, optimization, or any database-related tasks. (Tools: All tools)\n- unity-developer: Build Unity games with optimized C# scripts, efficient rendering, and proper asset management. Masters Unity 6 LTS, URP/HDRP pipelines, and cross-platform deployment. Handles gameplay systems, UI implementation, and platform optimization. Use PROACTIVELY for Unity performance issues, game mechanics, or cross-platform builds. (Tools: All tools)\n- skills-consolidation: Expert sub-agent for consolidating multiple related skills into comprehensive expert skills with zero information loss (Tools: All tools)\n- sales-automator: Draft cold emails, follow-ups, and proposal templates. Creates pricing pages, case studies, and sales scripts. Use PROACTIVELY for sales outreach or lead nurturing. (Tools: All tools)\n- javascript-pro: Master modern JavaScript with ES6+, async patterns, and Node.js APIs. Handles promises, event loops, and browser/Node compatibility. Use PROACTIVELY for JavaScript optimization, async debugging, or complex JS patterns. (Tools: All tools)\n- frontend-developer: Build React components, implement responsive layouts, and handle client-side state management. Masters React 19, Next.js 15, and modern frontend architecture. Optimizes performance and ensures accessibility. Use PROACTIVELY when creating UI components or fixing frontend issues. (Tools: All tools)\n- minecraft-bukkit-pro: Master Minecraft server plugin development with Bukkit, Spigot, and Paper APIs. Specializes in event-driven architecture, command systems, world manipulation, player management, and performance optimization. Use PROACTIVELY for plugin architecture, gameplay mechanics, server-side features, or cross-version compatibility. (Tools: All tools)\n- dx-optimizer: Developer Experience specialist. Improves tooling, setup, and workflows. Use PROACTIVELY when setting up new projects, after team feedback, or when development friction is noticed. (Tools: All tools)\n- payment-integration: Integrate Stripe, PayPal, and payment processors. Handles checkout flows, subscriptions, webhooks, and PCI compliance. Use PROACTIVELY when implementing payments, billing, or subscription features. (Tools: All tools)\n- test-automator: Master AI-powered test automation with modern frameworks, self-healing tests, and comprehensive quality engineering. Build scalable testing strategies with advanced CI/CD integration. Use PROACTIVELY for testing automation or quality assurance. (Tools: All tools)\n- ui-ux-designer: Create interface designs, wireframes, and design systems. Masters user research, accessibility standards, and modern design tools. Specializes in design tokens, component libraries, and inclusive design. Use PROACTIVELY for design systems, user flows, or interface optimization. (Tools: All tools)\n- incident-responder: Expert SRE incident responder specializing in rapid problem resolution, modern observability, and comprehensive incident management. Masters incident command, blameless post-mortems, error budget management, and system reliability patterns. Handles critical outages, communication strategies, and continuous improvement. Use IMMEDIATELY for production incidents or SRE practices. (Tools: All tools)\n- mlops-engineer: Build comprehensive ML pipelines, experiment tracking, and model registries with MLflow, Kubeflow, and modern MLOps tools. Implements automated training, deployment, and monitoring across cloud platforms. Use PROACTIVELY for ML infrastructure, experiment management, or pipeline automation. (Tools: All tools)\n- risk-manager: Monitor portfolio risk, R-multiples, and position limits. Creates hedging strategies, calculates expectancy, and implements stop-losses. Use PROACTIVELY for risk assessment, trade tracking, or portfolio protection. (Tools: All tools)\n- network-engineer: Expert network engineer specializing in modern cloud networking, security architectures, and performance optimization. Masters multi-cloud connectivity, service mesh, zero-trust networking, SSL/TLS, global load balancing, and advanced troubleshooting. Handles CDN optimization, network automation, and compliance. Use PROACTIVELY for network design, connectivity issues, or performance optimization. (Tools: All tools)\n- data-engineer: Build scalable data pipelines, modern data warehouses, and real-time streaming architectures. Implements Apache Spark, dbt, Airflow, and cloud-native data platforms. Use PROACTIVELY for data pipeline design, analytics infrastructure, or modern data stack implementation. (Tools: All tools)\n- flutter-expert: Master Flutter development with Dart 3, advanced widgets, and multi-platform deployment. Handles state management, animations, testing, and performance optimization for mobile, web, desktop, and embedded platforms. Use PROACTIVELY for Flutter architecture, UI implementation, or cross-platform features. (Tools: All tools)\n- hybrid-cloud-architect: Expert hybrid cloud architect specializing in complex multi-cloud solutions across AWS/Azure/GCP and private clouds (OpenStack/VMware). Masters hybrid connectivity, workload placement optimization, edge computing, and cross-cloud automation. Handles compliance, cost optimization, disaster recovery, and migration strategies. Use PROACTIVELY for hybrid architecture, multi-cloud strategy, or complex infrastructure integration. (Tools: All tools)\n- data-scientist: Expert data scientist for advanced analytics, machine learning, and statistical modeling. Handles complex data analysis, predictive modeling, and business intelligence. Use PROACTIVELY for data analysis tasks, ML modeling, statistical analysis, and data-driven insights. (Tools: All tools)\n- seo-structure-architect: Analyzes and optimizes content structure including header hierarchy, suggests schema markup, and internal linking opportunities. Creates search-friendly content organization. Use PROACTIVELY for content structuring. (Tools: All tools)\n- search-specialist: Expert web researcher using advanced search techniques and synthesis. Masters search operators, result filtering, and multi-source verification. Handles competitive analysis and fact-checking. Use PROACTIVELY for deep research, information gathering, or trend analysis. (Tools: All tools)\n- seo-content-planner: Creates comprehensive content outlines and topic clusters for SEO. Plans content calendars and identifies topic gaps. Use PROACTIVELY for content strategy and planning. (Tools: All tools)\n- elixir-pro: Write idiomatic Elixir code with OTP patterns, supervision trees, and Phoenix LiveView. Masters concurrency, fault tolerance, and distributed systems. Use PROACTIVELY for Elixir refactoring, OTP design, or complex BEAM optimizations. (Tools: All tools)\n- devops-troubleshooter: Expert DevOps troubleshooter specializing in rapid incident response, advanced debugging, and modern observability. Masters log analysis, distributed tracing, Kubernetes debugging, performance optimization, and root cause analysis. Handles production outages, system reliability, and preventive monitoring. Use PROACTIVELY for debugging, incident response, or system troubleshooting. (Tools: All tools)\n- cpp-pro: Write idiomatic C++ code with modern features, RAII, smart pointers, and STL algorithms. Handles templates, move semantics, and performance optimization. Use PROACTIVELY for C++ refactoring, memory safety, or complex C++ patterns. (Tools: All tools)\n- csharp-pro: Write modern C# code with advanced features like records, pattern matching, and async/await. Optimizes .NET applications, implements enterprise patterns, and ensures comprehensive testing. Use PROACTIVELY for C# refactoring, performance optimization, or complex .NET solutions. (Tools: All tools)\n- context-manager: Elite AI context engineering specialist mastering dynamic context management, vector databases, knowledge graphs, and intelligent memory systems. Orchestrates context across multi-agent workflows, enterprise AI systems, and long-running projects with 2024/2025 best practices. Use PROACTIVELY for complex AI orchestration. (Tools: All tools)\n- kubernetes-architect: Expert Kubernetes architect specializing in cloud-native infrastructure, advanced GitOps workflows (ArgoCD/Flux), and enterprise container orchestration. Masters EKS/AKS/GKE, service mesh (Istio/Linkerd), progressive delivery, multi-tenancy, and platform engineering. Handles security, observability, cost optimization, and developer experience. Use PROACTIVELY for K8s architecture, GitOps implementation, or cloud-native platform design. (Tools: All tools)\n- business-analyst: Master modern business analysis with AI-powered analytics, real-time dashboards, and data-driven insights. Build comprehensive KPI frameworks, predictive models, and strategic recommendations. Use PROACTIVELY for business intelligence or strategic analysis. (Tools: All tools)\n- quant-analyst: Build financial models, backtest trading strategies, and analyze market data. Implements risk metrics, portfolio optimization, and statistical arbitrage. Use PROACTIVELY for quantitative finance, trading algorithms, or risk analysis. (Tools: All tools)\n- seo-keyword-strategist: Analyzes keyword usage in provided content, calculates density, suggests semantic variations and LSI keywords based on the topic. Prevents over-optimization. Use PROACTIVELY for content optimization. (Tools: All tools)\n- hr-pro: Professional, ethical HR partner for hiring, onboarding/offboarding, PTO and leave, performance, compliant policies, and employee relations. Ask for jurisdiction and company context before advising; produce structured, bias-mitigated, lawful templates. (Tools: All tools)\n- seo-expert: Comprehensive SEO specialist covering content strategy, writing, optimization, technical SEO, E-E-A-T, and performance analysis. Handles all aspects of search engine optimization from planning to execution. Use PROACTIVELY for any SEO-related tasks. (Tools: All tools)\n- ai-engineer: Build production-ready LLM applications, advanced RAG systems, and intelligent agents. Implements vector search, multimodal AI, agent orchestration, and enterprise AI integrations. Use PROACTIVELY for LLM features, chatbots, AI agents, or AI-powered applications. (Tools: All tools)\n- docs-architect: Creates comprehensive technical documentation from existing codebases. Analyzes architecture, design patterns, and implementation details to produce long-form technical manuals and ebooks. Use PROACTIVELY for system documentation, architecture guides, or technical deep-dives. (Tools: All tools)\n- legacy-modernizer: Refactor legacy codebases, migrate outdated frameworks, and implement gradual modernization. Handles technical debt, dependency updates, and backward compatibility. Use PROACTIVELY for legacy system updates, framework migrations, or technical debt reduction. (Tools: All tools)\n- database-optimizer: Expert database optimizer specializing in modern performance tuning, query optimization, and scalable architectures. Masters advanced indexing, N+1 resolution, multi-tier caching, partitioning strategies, and cloud database optimization. Handles complex query analysis, migration strategies, and performance monitoring. Use PROACTIVELY for database optimization, performance issues, or scalability challenges. (Tools: All tools)\n- seo-content-writer: Writes SEO-optimized content based on provided keywords and topic briefs. Creates engaging, comprehensive content following best practices. Use PROACTIVELY for content creation tasks. (Tools: All tools)\n- api-documenter: Master API documentation with OpenAPI 3.1, AI-powered tools, and modern developer experience practices. Create interactive docs, generate SDKs, and build comprehensive developer portals. Use PROACTIVELY for API documentation or developer portal creation. (Tools: All tools)\n- java-pro: Master Java 21+ with modern features like virtual threads, pattern matching, and Spring Boot 3.x. Expert in the latest Java ecosystem including GraalVM, Project Loom, and cloud-native patterns. Use PROACTIVELY for Java development, microservices architecture, or performance optimization. (Tools: All tools)\n- python-pro: Master Python 3.12+ with modern features, async programming, performance optimization, and production-ready practices. Expert in the latest Python ecosystem including uv, ruff, pydantic, and FastAPI. Use PROACTIVELY for Python development, optimization, or advanced Python patterns. (Tools: All tools)\n- prompt-engineer: Expert prompt engineer specializing in advanced prompting techniques, LLM optimization, and AI system design. Masters chain-of-thought, constitutional AI, and production prompt strategies. Use when building AI features, improving agent performance, or crafting system prompts. (Tools: All tools)\n- typescript-pro: Master TypeScript with advanced types, generics, and strict type safety. Handles complex type systems, decorators, and enterprise-grade patterns. Use PROACTIVELY for TypeScript architecture, type inference optimization, or advanced typing patterns. (Tools: All tools)\n- django-pro: Master Django 5.x with async views, DRF, Celery, and Django Channels. Build scalable web applications with proper architecture, testing, and deployment. Use PROACTIVELY for Django development, ORM optimization, or complex Django patterns. (Tools: All tools)\n- tdd-orchestrator: Master TDD orchestrator specializing in red-green-refactor discipline, multi-agent workflow coordination, and comprehensive test-driven development practices. Enforces TDD best practices across teams with AI-assisted testing and modern frameworks. Use PROACTIVELY for TDD implementation and governance. (Tools: All tools)\n- mobile-security-coder: Expert in secure mobile coding practices specializing in input validation, WebView security, and mobile-specific security patterns. Use PROACTIVELY for mobile security implementations or mobile security code reviews. (Tools: All tools)\n- julia-pro: Master Julia 1.10+ with modern features, performance optimization, multiple dispatch, and production-ready practices. Expert in the Julia ecosystem including package management, scientific computing, and high-performance numerical code. Use PROACTIVELY for Julia development, optimization, or advanced Julia patterns. (Tools: All tools)\n- performance-engineer: Expert performance engineer specializing in modern observability, application optimization, and scalable system performance. Masters OpenTelemetry, distributed tracing, load testing, multi-tier caching, Core Web Vitals, and performance monitoring. Handles end-to-end optimization, real user monitoring, and scalability patterns. Use PROACTIVELY for performance optimization, observability, or scalability challenges. (Tools: All tools)\n- database-architect: Expert database architect specializing in data layer design from scratch, technology selection, schema modeling, and scalable database architectures. Masters SQL/NoSQL/TimeSeries database selection, normalization strategies, migration planning, and performance-first design. Handles both greenfield architectures and re-architecture of existing systems. Use PROACTIVELY for database architecture, technology selection, or data modeling decisions. (Tools: All tools)\n- bash-pro: Master of defensive Bash scripting for production automation, CI/CD pipelines, and system utilities. Expert in safe, portable, and testable shell scripts. (Tools: All tools)\n- mermaid-expert: Create Mermaid diagrams for flowcharts, sequences, ERDs, and architectures. Masters syntax for all diagram types and styling. Use PROACTIVELY for visual documentation, system diagrams, or process flows. (Tools: All tools)\n- seo-content-refresher: Identifies outdated elements in provided content and suggests updates to maintain freshness. Finds statistics, dates, and examples that need updating. Use PROACTIVELY for older content. (Tools: All tools)\n- seo-authority-builder: Analyzes content for E-E-A-T signals and suggests improvements to build authority and trust. Identifies missing credibility elements. Use PROACTIVELY for YMYL topics. (Tools: All tools)\n- blockchain-developer: Build production-ready Web3 applications, smart contracts, and decentralized systems. Implements DeFi protocols, NFT platforms, DAOs, and enterprise blockchain integrations. Use PROACTIVELY for smart contracts, Web3 apps, DeFi protocols, or blockchain infrastructure. (Tools: All tools)\n- system-architect: Master software architect specializing in modern architecture patterns, clean architecture, microservices, event-driven systems, DDD, and comprehensive technical documentation. Reviews system designs for architectural integrity, scalability, and maintainability. Creates long-form technical documentation from codebases. Use PROACTIVELY for architectural decisions, system design reviews, or technical documentation. (Tools: All tools)\n- backend-security-coder: Expert in secure backend coding practices specializing in input validation, authentication, and API security. Use PROACTIVELY for backend security implementations or security code reviews. (Tools: All tools)\n- code-reviewer: Elite code review expert specializing in modern AI-powered code analysis, security vulnerabilities, performance optimization, and production reliability. Masters static analysis tools, security scanning, and configuration review with 2024/2025 best practices. Use PROACTIVELY for code quality assurance. (Tools: All tools)\n- architect-review: Master software architect specializing in modern architecture patterns, clean architecture, microservices, event-driven systems, and DDD. Reviews system designs and code changes for architectural integrity, scalability, and maintainability. Use PROACTIVELY for architectural decisions. (Tools: All tools)\n- terraform-specialist: Expert Terraform/OpenTofu specialist mastering advanced IaC automation, state management, and enterprise infrastructure patterns. Handles complex module design, multi-cloud deployments, GitOps workflows, policy as code, and CI/CD integration. Covers migration strategies, security best practices, and modern IaC ecosystems. Use PROACTIVELY for advanced IaC, state management, or infrastructure automation. (Tools: All tools)\n- seo-meta-optimizer: Creates optimized meta titles, descriptions, and URL suggestions based on character limits and best practices. Generates compelling, keyword-rich metadata. Use PROACTIVELY for new content. (Tools: All tools)\n- customer-support: Elite AI-powered customer support specialist mastering conversational AI, automated ticketing, sentiment analysis, and omnichannel support experiences. Integrates modern support tools, chatbot platforms, and CX optimization with 2024/2025 best practices. Use PROACTIVELY for comprehensive customer experience management. (Tools: All tools)\n- c-pro: Write efficient C code with proper memory management, pointer arithmetic, and system calls. Handles embedded systems, kernel modules, and performance-critical code. Use PROACTIVELY for C optimization, memory issues, or system programming. (Tools: All tools)\n- ruby-pro: Write idiomatic Ruby code with metaprogramming, Rails patterns, and performance optimization. Specializes in Ruby on Rails, gem development, and testing frameworks. Use PROACTIVELY for Ruby refactoring, optimization, or complex Ruby features. (Tools: All tools)\n\nWhen using the Task tool, you must specify a subagent_type parameter to select which agent type to use.\n\nWhen NOT to use the Task tool:\n- If you want to read a specific file path, use the Read or Glob tool instead of the Task tool, to find the match more quickly\n- If you are searching for a specific class definition like \"class Foo\", use the Glob tool instead, to find the match more quickly\n- If you are searching for code within a specific file or set of 2-3 files, use the Read tool instead of the Task tool, to find the match more quickly\n- Other tasks that are not related to the agent descriptions above\n\n\nUsage notes:\n- Launch multiple agents concurrently whenever possible, to maximize performance; to do that, use a single message with multiple tool uses\n- When the agent is done, it will return a single message back to you. The result returned by the agent is not visible to the user. To show the user the result, you should send a text message back to the user with a concise summary of the result.\n- Each agent invocation is stateless. You will not be able to send additional messages to the agent, nor will the agent be able to communicate with you outside of its final report. Therefore, your prompt should contain a highly detailed task description for the agent to perform autonomously and you should specify exactly what information the agent should return back to you in its final and only message to you.\n- Agents with \"access to current context\" can see the full conversation history before the tool call. When using these agents, you can write concise prompts that reference earlier context (e.g., \"investigate the error discussed above\") instead of repeating information. The agent will receive all prior messages and understand the context.\n- The agent's outputs should generally be trusted\n- Clearly tell the agent whether you expect it to write code or just to do research (search, file reads, web fetches, etc.), since it is not aware of the user's intent\n- If the agent description mentions that it should be used proactively, then you should try your best to use it without the user having to ask for it first. Use your judgement.\n- If the user specifies that they want you to run agents \"in parallel\", you MUST send a single message with multiple Task tool use content blocks. For example, if you need to launch both a code-reviewer agent and a test-runner agent in parallel, send a single message with both tool calls.\n\nExample usage:\n\n<example_agent_descriptions>\n\"code-reviewer\": use this agent after you are done writing a signficant piece of code\n\"greeting-responder\": use this agent when to respond to user greetings with a friendly joke\n</example_agent_description>\n\n<example>\nuser: \"Please write a function that checks if a number is prime\"\nassistant: Sure let me write a function that checks if a number is prime\nassistant: First let me use the Write tool to write a function that checks if a number is prime\nassistant: I'm going to use the Write tool to write the following code:\n<code>\nfunction isPrime(n) {\n  if (n <= 1) return false\n  for (let i = 2; i * i <= n; i++) {\n    if (n % i === 0) return false\n  }\n  return true\n}\n</code>\n<commentary>\nSince a signficant piece of code was written and the task was completed, now use the code-reviewer agent to review the code\n</commentary>\nassistant: Now let me use the code-reviewer agent to review the code\nassistant: Uses the Task tool to launch the code-reviewer agent \n</example>\n\n<example>\nuser: \"Hello\"\n<commentary>\nSince the user is greeting, use the greeting-responder agent to respond with a friendly joke\n</commentary>\nassistant: \"I'm going to use the Task tool to launch the greeting-responder agent\"\n</example>\n",
      "input_schema": {
        "type": "object",
        "properties": {
          "subagent_type": {
            "type": "string",
            "description": "The type of specialized agent to use for this task"
          },
          "model": {
            "enum": [
              "sonnet",
              "opus",
              "haiku"
            ],
            "description": "Optional model to use for this agent. If not specified, inherits from parent. Prefer haiku for quick, straightforward tasks to minimize cost and latency.",
            "type": "string"
          },
          "resume": {
            "type": "string",
            "description": "Optional agent ID to resume from. If provided, the agent will continue from the previous execution transcript."
          },
          "description": {
            "type": "string",
            "description": "A short (3-5 word) description of the task"
          },
          "prompt": {
            "type": "string",
            "description": "The task for the agent to perform"
          }
        },
        "required": [
          "description",
          "prompt",
          "subagent_type"
        ],
        "additionalProperties": false,
        "$schema": "http://json-schema.org/draft-07/schema#"
      },
      "name": "Task"
    },
    {
      "description": "Executes a given bash command in a persistent shell session with optional timeout, ensuring proper handling and security measures.\n\nIMPORTANT: This tool is for terminal operations like git, npm, docker, etc. DO NOT use it for file operations (reading, writing, editing, searching, finding files) - use the specialized tools for this instead.\n\nBefore executing the command, please follow these steps:\n\n1. Directory Verification:\n   - If the command will create new directories or files, first use `ls` to verify the parent directory exists and is the correct location\n   - For example, before running \"mkdir foo/bar\", first use `ls foo` to check that \"foo\" exists and is the intended parent directory\n\n2. Command Execution:\n   - Always quote file paths that contain spaces with double quotes (e.g., cd \"path with spaces/file.txt\")\n   - Examples of proper quoting:\n     - cd \"/Users/name/My Documents\" (correct)\n     - cd /Users/name/My Documents (incorrect - will fail)\n     - python \"/path/with spaces/script.py\" (correct)\n     - python /path/with spaces/script.py (incorrect - will fail)\n   - After ensuring proper quoting, execute the command.\n   - Capture the output of the command.\n\nUsage notes:\n  - The command argument is required.\n  - You can specify an optional timeout in milliseconds (up to 300000ms / 5 minutes). If not specified, commands will timeout after 30000ms (0.5 minutes).\n  - It is very helpful if you write a clear, concise description of what this command does in 5-10 words.\n  - If the output exceeds 30000 characters, output will be truncated before being returned to you.\n  - You can use the `run_in_background` parameter to run the command in the background, which allows you to continue working while the command runs. You can monitor the output using the Bash tool as it becomes available. You do not need to use '&' at the end of the command when using this parameter.\n  \n  - Avoid using Bash with the `find`, `grep`, `cat`, `head`, `tail`, `sed`, `awk`, or `echo` commands, unless explicitly instructed or when these commands are truly necessary for the task. Instead, always prefer using the dedicated tools for these commands:\n    - File search: Use Glob (NOT find or ls)\n    - Content search: Use Grep (NOT grep or rg)\n    - Read files: Use Read (NOT cat/head/tail)\n    - Edit files: Use Edit (NOT sed/awk)\n    - Write files: Use Write (NOT echo >/cat <<EOF)\n    - Communication: Output text directly (NOT echo/printf)\n  - When issuing multiple commands:\n    - If the commands are independent and can run in parallel, make multiple Bash tool calls in a single message. For example, if you need to run \"git status\" and \"git diff\", send a single message with two Bash tool calls in parallel.\n    - If the commands depend on each other and must run sequentially, use a single Bash call with '&&' to chain them together (e.g., `git add . && git commit -m \"message\" && git push`). For instance, if one operation must complete before another starts (like mkdir before cp, Write before Bash for git operations, or git add before git commit), run these operations sequentially instead.\n    - Use ';' only when you need to run commands sequentially but don't care if earlier commands fail\n    - DO NOT use newlines to separate commands (newlines are ok in quoted strings)\n  - Try to maintain your current working directory throughout the session by using absolute paths and avoiding usage of `cd`. You may use `cd` if the User explicitly requests it.\n    <good-example>\n    pytest /foo/bar/tests\n    </good-example>\n    <bad-example>\n    cd /foo/bar && pytest tests\n    </bad-example>\n\n# Committing changes with git\n\nOnly create commits when requested by the user. If unclear, ask first. When the user asks you to create a new git commit, follow these steps carefully:\n\nGit Safety Protocol:\n- NEVER update the git config\n- NEVER run destructive/irreversible git commands (like push --force, hard reset, etc) unless the user explicitly requests them \n- NEVER skip hooks (--no-verify, --no-gpg-sign, etc) unless the user explicitly requests it\n- NEVER run force push to main/master, warn the user if they request it\n- Avoid git commit --amend.  ONLY use --amend when either (1) user explicitly requested amend OR (2) adding edits from pre-commit hook (additional instructions below) \n- Before amending: ALWAYS check authorship (git log -1 --format='%an %ae')\n- NEVER commit changes unless the user explicitly asks you to. It is VERY IMPORTANT to only commit when explicitly asked, otherwise the user will feel that you are being too proactive.\n\n1. You can call multiple tools in a single response. When multiple independent pieces of information are requested and all commands are likely to succeed, run multiple tool calls in parallel for optimal performance. run the following bash commands in parallel, each using the Bash tool:\n  - Run a git status command to see all untracked files.\n  - Run a git diff command to see both staged and unstaged changes that will be committed.\n  - Run a git log command to see recent commit messages, so that you can follow this repository's commit message style.\n2. Analyze all staged changes (both previously staged and newly added) and draft a commit message:\n  - Summarize the nature of the changes (eg. new feature, enhancement to an existing feature, bug fix, refactoring, test, docs, etc.). Ensure the message accurately reflects the changes and their purpose (i.e. \"add\" means a wholly new feature, \"update\" means an enhancement to an existing feature, \"fix\" means a bug fix, etc.).\n  - Do not commit files that likely contain secrets (.env, credentials.json, etc). Warn the user if they specifically request to commit those files\n  - Draft a concise (1-2 sentences) commit message that focuses on the \"why\" rather than the \"what\"\n  - Ensure it accurately reflects the changes and their purpose\n3. You can call multiple tools in a single response. When multiple independent pieces of information are requested and all commands are likely to succeed, run multiple tool calls in parallel for optimal performance. run the following commands:\n   - Add relevant untracked files to the staging area.\n   - Create the commit with a message.\n   - Run git status after the commit completes to verify success.\n   Note: git status depends on the commit completing, so run it sequentially after the commit.\n4. If the commit fails due to pre-commit hook changes, retry ONCE. If it succeeds but files were modified by the hook, verify it's safe to amend:\n   - Check authorship: git log -1 --format='%an %ae'\n   - Check not pushed: git status shows \"Your branch is ahead\"\n   - If both true: amend your commit. Otherwise: create NEW commit (never amend other developers' commits)\n\nImportant notes:\n- NEVER run additional commands to read or explore code, besides git bash commands\n- NEVER use the TodoWrite or Task tools\n- DO NOT push to the remote repository unless the user explicitly asks you to do so\n- IMPORTANT: Never use git commands with the -i flag (like git rebase -i or git add -i) since they require interactive input which is not supported.\n- If there are no changes to commit (i.e., no untracked files and no modifications), do not create an empty commit\n- In order to ensure good formatting, ALWAYS pass the commit message via a HEREDOC, a la this example:\n<example>\ngit commit -m \"$(cat <<'EOF'\n   Commit message here.\n   EOF\n   )\"\n</example>\n\n# Creating pull requests\nUse the gh command via the Bash tool for ALL GitHub-related tasks including working with issues, pull requests, checks, and releases. If given a Github URL use the gh command to get the information needed.\n\nIMPORTANT: When the user asks you to create a pull request, follow these steps carefully:\n\n1. You can call multiple tools in a single response. When multiple independent pieces of information are requested and all commands are likely to succeed, run multiple tool calls in parallel for optimal performance. run the following bash commands in parallel using the Bash tool, in order to understand the current state of the branch since it diverged from the main branch:\n   - Run a git status command to see all untracked files\n   - Run a git diff command to see both staged and unstaged changes that will be committed\n   - Check if the current branch tracks a remote branch and is up to date with the remote, so you know if you need to push to the remote\n   - Run a git log command and `git diff [base-branch]...HEAD` to understand the full commit history for the current branch (from the time it diverged from the base branch)\n2. Analyze all changes that will be included in the pull request, making sure to look at all relevant commits (NOT just the latest commit, but ALL commits that will be included in the pull request!!!), and draft a pull request summary\n3. You can call multiple tools in a single response. When multiple independent pieces of information are requested and all commands are likely to succeed, run multiple tool calls in parallel for optimal performance. run the following commands in parallel:\n   - Create new branch if needed\n   - Push to remote with -u flag if needed\n   - Create PR using gh pr create with the format below. Use a HEREDOC to pass the body to ensure correct formatting.\n<example>\ngh pr create --title \"the pr title\" --body \"$(cat <<'EOF'\n## Summary\n<1-3 bullet points>\n\n## Test plan\n[Bulleted markdown checklist of TODOs for testing the pull request...]\nEOF\n)\"\n</example>\n\nImportant:\n- DO NOT use the TodoWrite or Task tools\n- Return the PR URL when you're done, so the user can see it\n\n# Other common operations\n- View comments on a Github PR: gh api repos/foo/bar/pulls/123/comments",
      "input_schema": {
        "additionalProperties": false,
        "$schema": "http://json-schema.org/draft-07/schema#",
        "type": "object",
        "properties": {
          "dangerouslyDisableSandbox": {
            "type": "boolean",
            "description": "Set this to true to dangerously override sandbox mode and run commands without sandboxing."
          },
          "command": {
            "description": "The command to execute",
            "type": "string"
          },
          "timeout": {
            "type": "number",
            "description": "Optional timeout in milliseconds (max 600000)"
          },
          "description": {
            "type": "string",
            "description": "Clear, concise description of what this command does in 5-10 words, in active voice. Examples:\nInput: ls\nOutput: List files in current directory\n\nInput: git status\nOutput: Show working tree status\n\nInput: npm install\nOutput: Install package dependencies\n\nInput: mkdir foo\nOutput: Create directory 'foo'"
          },
          "run_in_background": {
            "type": "boolean",
            "description": "Set to true to run this command in the background. Use BashOutput to read the output later."
          }
        },
        "required": [
          "command"
        ]
      },
      "name": "Bash"
    },
    {
      "name": "Glob",
      "description": "- Fast file pattern matching tool that works with any codebase size\n- Supports glob patterns like \"**/*.js\" or \"src/**/*.ts\"\n- Returns matching file paths sorted by modification time\n- Use this tool when you need to find files by name patterns\n- When you are doing an open ended search that may require multiple rounds of globbing and grepping, use the Agent tool instead\n- You can call multiple tools in a single response. It is always better to speculatively perform multiple searches in parallel if they are potentially useful.",
      "input_schema": {
        "required": [
          "pattern"
        ],
        "additionalProperties": false,
        "$schema": "http://json-schema.org/draft-07/schema#",
        "type": "object",
        "properties": {
          "pattern": {
            "description": "The glob pattern to match files against",
            "type": "string"
          },
          "path": {
            "type": "string",
            "description": "The directory to search in. If not specified, the current working directory will be used. IMPORTANT: Omit this field to use the default directory. DO NOT enter \"undefined\" or \"null\" - simply omit it for the default behavior. Must be a valid directory path if provided."
          }
        }
      }
    },
    {
      "description": "A powerful search tool built on ripgrep\n\n  Usage:\n  - ALWAYS use Grep for search tasks. NEVER invoke `grep` or `rg` as a Bash command. The Grep tool has been optimized for correct permissions and access.\n  - Supports full regex syntax (e.g., \"log.*Error\", \"function\\s+\\w+\")\n  - Filter files with glob parameter (e.g., \"*.js\", \"**/*.tsx\") or type parameter (e.g., \"js\", \"py\", \"rust\")\n  - Output modes: \"content\" shows matching lines, \"files_with_matches\" shows only file paths (default), \"count\" shows match counts\n  - Use Task tool for open-ended searches requiring multiple rounds\n  - Pattern syntax: Uses ripgrep (not grep) - literal braces need escaping (use `interface\\{\\}` to find `interface{}` in Go code)\n  - Multiline matching: By default patterns match within single lines only. For cross-line patterns like `struct \\{[\\s\\S]*?field`, use `multiline: true`\n",
      "input_schema": {
        "type": "object",
        "properties": {
          "-C": {
            "type": "number",
            "description": "Number of lines to show before and after each match (rg -C). Requires output_mode: \"content\", ignored otherwise."
          },
          "-B": {
            "type": "number",
            "description": "Number of lines to show before each match (rg -B). Requires output_mode: \"content\", ignored otherwise."
          },
          "path": {
            "type": "string",
            "description": "File or directory to search in (rg PATH). Defaults to current working directory."
          },
          "-A": {
            "description": "Number of lines to show after each match (rg -A). Requires output_mode: \"content\", ignored otherwise.",
            "type": "number"
          },
          "-n": {
            "type": "boolean",
            "description": "Show line numbers in output (rg -n). Requires output_mode: \"content\", ignored otherwise. Defaults to true."
          },
          "pattern": {
            "type": "string",
            "description": "The regular expression pattern to search for in file contents"
          },
          "offset": {
            "description": "Skip first N lines/entries before applying head_limit, equivalent to \"| tail -n +N | head -N\". Works across all output modes. Defaults to 0.",
            "type": "number"
          },
          "output_mode": {
            "type": "string",
            "enum": [
              "content",
              "files_with_matches",
              "count"
            ],
            "description": "Output mode: \"content\" shows matching lines (supports -A/-B/-C context, -n line numbers, head_limit), \"files_with_matches\" shows file paths (supports head_limit), \"count\" shows match counts (supports head_limit). Defaults to \"files_with_matches\"."
          },
          "-i": {
            "description": "Case insensitive search (rg -i)",
            "type": "boolean"
          },
          "multiline": {
            "type": "boolean",
            "description": "Enable multiline mode where . matches newlines and patterns can span lines (rg -U --multiline-dotall). Default: false."
          },
          "glob": {
            "type": "string",
            "description": "Glob pattern to filter files (e.g. \"*.js\", \"*.{ts,tsx}\") - maps to rg --glob"
          },
          "type": {
            "type": "string",
            "description": "File type to search (rg --type). Common types: js, py, rust, go, java, etc. More efficient than include for standard file types."
          },
          "head_limit": {
            "type": "number",
            "description": "Limit output to first N lines/entries, equivalent to \"| head -N\". Works across all output modes: content (limits output lines), files_with_matches (limits file paths), count (limits count entries). Defaults based on \"cap\" experiment value: 0 (unlimited), 20, or 100."
          }
        },
        "required": [
          "pattern"
        ],
        "additionalProperties": false,
        "$schema": "http://json-schema.org/draft-07/schema#"
      },
      "name": "Grep"
    },
    {
      "name": "ExitPlanMode",
      "description": "Use this tool when you are in plan mode and have finished presenting your plan and are ready to code. This will prompt the user to exit plan mode.\nIMPORTANT: Only use this tool when the task requires planning the implementation steps of a task that requires writing code. For research tasks where you're gathering information, searching files, reading files or in general trying to understand the codebase - do NOT use this tool.\n\n## Handling Ambiguity in Plans\nBefore using this tool, ensure your plan is clear and unambiguous. If there are multiple valid approaches or unclear requirements:\n1. Use the AskUserQuestion tool to clarify with the user\n2. Ask about specific implementation choices (e.g., architectural patterns, which library to use)\n3. Clarify any assumptions that could affect the implementation\n4. Only proceed with ExitPlanMode after resolving ambiguities\n\n## Examples\n\n1. Initial task: \"Search for and understand the implementation of vim mode in the codebase\" - Do not use the exit plan mode tool because you are not planning the implementation steps of a task.\n2. Initial task: \"Help me implement yank mode for vim\" - Use the exit plan mode tool after you have finished planning the implementation steps of the task.\n3. Initial task: \"Add a new feature to handle user authentication\" - If unsure about auth method (OAuth, JWT, etc.), use AskUserQuestion first, then use exit plan mode tool after clarifying the approach.\n",
      "input_schema": {
        "properties": {
          "plan": {
            "description": "The plan you came up with, that you want to run by the user for approval. Supports markdown. The plan should be pretty concise.",
            "type": "string"
          }
        },
        "required": [
          "plan"
        ],
        "additionalProperties": false,
        "$schema": "http://json-schema.org/draft-07/schema#",
        "type": "object"
      }
    },
    {
      "name": "Read",
      "description": "Reads a file from the local filesystem. You can access any file directly by using this tool.\nAssume this tool is able to read all files on the machine. If the User provides a path to a file assume that path is valid. It is okay to read a file that does not exist; an error will be returned.\n\nUsage:\n- The file_path parameter must be an absolute path, not a relative path\n- By default, it reads up to 2000 lines starting from the beginning of the file\n- You can optionally specify a line offset and limit (especially handy for long files), but it's recommended to read the whole file by not providing these parameters\n- Any lines longer than 2000 characters will be truncated\n- Results are returned using cat -n format, with line numbers starting at 1\n- This tool allows Claude Code to read images (eg PNG, JPG, etc). When reading an image file the contents are presented visually as Claude Code is a multimodal LLM.\n- This tool can read PDF files (.pdf). PDFs are processed page by page, extracting both text and visual content for analysis.\n- This tool can read Jupyter notebooks (.ipynb files) and returns all cells with their outputs, combining code, text, and visualizations.\n- This tool can only read files, not directories. To read a directory, use an ls command via the Bash tool.\n- You can call multiple tools in a single response. It is always better to speculatively read multiple potentially useful files in parallel.\n- You will regularly be asked to read screenshots. If the user provides a path to a screenshot, ALWAYS use this tool to view the file at the path. This tool will work with all temporary file paths.\n- If you read a file that exists but has empty contents you will receive a system reminder warning in place of file contents.",
      "input_schema": {
        "properties": {
          "file_path": {
            "type": "string",
            "description": "The absolute path to the file to read"
          },
          "offset": {
            "type": "number",
            "description": "The line number to start reading from. Only provide if the file is too large to read at once"
          },
          "limit": {
            "type": "number",
            "description": "The number of lines to read. Only provide if the file is too large to read at once."
          }
        },
        "required": [
          "file_path"
        ],
        "additionalProperties": false,
        "$schema": "http://json-schema.org/draft-07/schema#",
        "type": "object"
      }
    },
    {
      "name": "Edit",
      "description": "Performs exact string replacements in files. \n\nUsage:\n- You must use your `Read` tool at least once in the conversation before editing. This tool will error if you attempt an edit without reading the file. \n- When editing text from Read tool output, ensure you preserve the exact indentation (tabs/spaces) as it appears AFTER the line number prefix. The line number prefix format is: spaces + line number + tab. Everything after that tab is the actual file content to match. Never include any part of the line number prefix in the old_string or new_string.\n- ALWAYS prefer editing existing files in the codebase. NEVER write new files unless explicitly required.\n- Only use emojis if the user explicitly requests it. Avoid adding emojis to files unless asked.\n- The edit will FAIL if `old_string` is not unique in the file. Either provide a larger string with more surrounding context to make it unique or use `replace_all` to change every instance of `old_string`. \n- Use `replace_all` for replacing and renaming strings across the file. This parameter is useful if you want to rename a variable for instance.",
      "input_schema": {
        "$schema": "http://json-schema.org/draft-07/schema#",
        "type": "object",
        "properties": {
          "file_path": {
            "type": "string",
            "description": "The absolute path to the file to modify"
          },
          "old_string": {
            "description": "The text to replace",
            "type": "string"
          },
          "new_string": {
            "type": "string",
            "description": "The text to replace it with (must be different from old_string)"
          },
          "replace_all": {
            "type": "boolean",
            "default": false,
            "description": "Replace all occurences of old_string (default false)"
          }
        },
        "required": [
          "file_path",
          "old_string",
          "new_string"
        ],
        "additionalProperties": false
      }
    },
    {
      "name": "Write",
      "description": "Writes a file to the local filesystem.\n\nUsage:\n- This tool will overwrite the existing file if there is one at the provided path.\n- If this is an existing file, you MUST use the Read tool first to read the file's contents. This tool will fail if you did not read the file first.\n- ALWAYS prefer editing existing files in the codebase. NEVER write new files unless explicitly required.\n- NEVER proactively create documentation files (*.md) or README files. Only create documentation files if explicitly requested by the User.\n- Only use emojis if the user explicitly requests it. Avoid writing emojis to files unless asked.",
      "input_schema": {
        "properties": {
          "content": {
            "type": "string",
            "description": "The content to write to the file"
          },
          "file_path": {
            "type": "string",
            "description": "The absolute path to the file to write (must be absolute, not relative)"
          }
        },
        "required": [
          "file_path",
          "content"
        ],
        "additionalProperties": false,
        "$schema": "http://json-schema.org/draft-07/schema#",
        "type": "object"
      }
    },
    {
      "description": "Completely replaces the contents of a specific cell in a Jupyter notebook (.ipynb file) with new source. Jupyter notebooks are interactive documents that combine code, text, and visualizations, commonly used for data analysis and scientific computing. The notebook_path parameter must be an absolute path, not a relative path. The cell_number is 0-indexed. Use edit_mode=insert to add a new cell at the index specified by cell_number. Use edit_mode=delete to delete the cell at the index specified by cell_number.",
      "input_schema": {
        "$schema": "http://json-schema.org/draft-07/schema#",
        "type": "object",
        "properties": {
          "notebook_path": {
            "type": "string",
            "description": "The absolute path to the Jupyter notebook file to edit (must be absolute, not relative)"
          },
          "cell_id": {
            "description": "The ID of the cell to edit. When inserting a new cell, the new cell will be inserted after the cell with this ID, or at the beginning if not specified.",
            "type": "string"
          },
          "new_source": {
            "type": "string",
            "description": "The new source for the cell"
          },
          "cell_type": {
            "type": "string",
            "enum": [
              "code",
              "markdown"
            ],
            "description": "The type of the cell (code or markdown). If not specified, it defaults to the current cell type. If using edit_mode=insert, this is required."
          },
          "edit_mode": {
            "description": "The type of edit to make (replace, insert, delete). Defaults to replace.",
            "type": "string",
            "enum": [
              "replace",
              "insert",
              "delete"
            ]
          }
        },
        "required": [
          "notebook_path",
          "new_source"
        ],
        "additionalProperties": false
      },
      "name": "NotebookEdit"
    },
    {
      "name": "WebFetch",
      "description": "\n- Fetches content from a specified URL and processes it using an AI model\n- Takes a URL and a prompt as input\n- Fetches the URL content, converts HTML to markdown\n- Processes the content with the prompt using a small, fast model\n- Returns the model's response about the content\n- Use this tool when you need to retrieve and analyze web content\n\nUsage notes:\n  - IMPORTANT: If an MCP-provided web fetch tool is available, prefer using that tool instead of this one, as it may have fewer restrictions. All MCP-provided tools start with \"mcp__\".\n  - The URL must be a fully-formed valid URL\n  - HTTP URLs will be automatically upgraded to HTTPS\n  - The prompt should describe what information you want to extract from the page\n  - This tool is read-only and does not modify any files\n  - Results may be summarized if the content is very large\n  - Includes a self-cleaning 15-minute cache for faster responses when repeatedly accessing the same URL\n  - When a URL redirects to a different host, the tool will inform you and provide the redirect URL in a special format. You should then make a new WebFetch request with the redirect URL to fetch the content.\n",
      "input_schema": {
        "additionalProperties": false,
        "$schema": "http://json-schema.org/draft-07/schema#",
        "type": "object",
        "properties": {
          "url": {
            "format": "uri",
            "description": "The URL to fetch content from",
            "type": "string"
          },
          "prompt": {
            "type": "string",
            "description": "The prompt to run on the fetched content"
          }
        },
        "required": [
          "url",
          "prompt"
        ]
      }
    },
    {
      "description": "Use this tool to create and manage a structured task list for your current coding session. This helps you track progress, organize complex tasks, and demonstrate thoroughness to the user.\nIt also helps the user understand the progress of the task and overall progress of their requests.\n\n## When to Use This Tool\nUse this tool proactively in these scenarios:\n\n1. Complex multi-step tasks - When a task requires 3 or more distinct steps or actions\n2. Non-trivial and complex tasks - Tasks that require careful planning or multiple operations\n3. User explicitly requests todo list - When the user directly asks you to use the todo list\n4. User provides multiple tasks - When users provide a list of things to be done (numbered or comma-separated)\n5. After receiving new instructions - Immediately capture user requirements as todos\n6. When you start working on a task - Mark it as in_progress BEFORE beginning work. Ideally you should only have one todo as in_progress at a time\n7. After completing a task - Mark it as completed and add any new follow-up tasks discovered during implementation\n\n## When NOT to Use This Tool\n\nSkip using this tool when:\n1. There is only a single, straightforward task\n2. The task is trivial and tracking it provides no organizational benefit\n3. The task can be completed in less than 3 trivial steps\n4. The task is purely conversational or informational\n\nNOTE that you should not use this tool if there is only one trivial task to do. In this case you are better off just doing the task directly.\n\n## Examples of When to Use the Todo List\n\n<example>\nUser: I want to add a dark mode toggle to the application settings. Make sure you run the tests and build when you're done!\nAssistant: I'll help add a dark mode toggle to your application settings. Let me create a todo list to track this implementation.\n*Creates todo list with the following items:*\n1. Creating dark mode toggle component in Settings page\n2. Adding dark mode state management (context/store)\n3. Implementing CSS-in-JS styles for dark theme\n4. Updating existing components to support theme switching\n5. Running tests and build process, addressing any failures or errors that occur\n*Begins working on the first task*\n\n<reasoning>\nThe assistant used the todo list because:\n1. Adding dark mode is a multi-step feature requiring UI, state management, and styling changes\n2. The user explicitly requested tests and build be run afterward\n3. The assistant inferred that tests and build need to pass by adding \"Ensure tests and build succeed\" as the final task\n</reasoning>\n</example>\n\n<example>\nUser: Help me rename the function getCwd to getCurrentWorkingDirectory across my project\nAssistant: Let me first search through your codebase to find all occurrences of 'getCwd'.\n*Uses grep or search tools to locate all instances of getCwd in the codebase*\nAssistant: I've found 15 instances of 'getCwd' across 8 different files. Let me create a todo list to track these changes.\n*Creates todo list with specific items for each file that needs updating*\n\n<reasoning>\nThe assistant used the todo list because:\n1. First, the assistant searched to understand the scope of the task\n2. Upon finding multiple occurrences across different files, it determined this was a complex task with multiple steps\n3. The todo list helps ensure every instance is tracked and updated systematically\n4. This approach prevents missing any occurrences and maintains code consistency\n</reasoning>\n</example>\n\n\n<example>\nUser: I need to implement these features for my e-commerce site: user registration, product catalog, shopping cart, and checkout flow.\nAssistant: I'll help implement these features. First, let's add all the features to the todo list.\n*Creates a todo list breaking down each feature into specific tasks based on the project architecture*\nAssistant: Let's start with user registration. This will involve creating database models, API endpoints, and frontend forms that integrate with your existing authentication system.\n\n<reasoning>\nThe assistant used the todo list because:\n1. The user provided multiple complex features to implement in a comma separated list\n2. The todo list helps organize these large features into manageable tasks\n3. This approach allows for tracking progress across the entire implementation\n</reasoning>\n</example>\n\n<example>\nUser: Can you help optimize my React application? It's rendering slowly and has performance issues.</user>\nAssistant: I'll help optimize your React application. First, let me examine your codebase to identify potential performance bottlenecks.\n*Reviews component structure, render patterns, state management, and data fetching*\nAssistant: After analyzing your codebase, I've identified several performance issues. Let me create a todo list to track our optimization efforts.\n*Creates todo list with items like: 1) Implementing memoization for expensive calculations in ProductList, 2) Adding virtualization for long lists in Dashboard, 3) Optimizing image loading in Gallery component, 4) Fixing state update loops in ShoppingCart, 5) Reviewing bundle size and implementing code splitting*\nLet's start by implementing memoization for the expensive calculations in your ProductList component.</assistant>\n\n<reasoning>\nThe assistant used the todo list because:\n1. First, the assistant examined the codebase to identify specific performance issues\n2. Based on this analysis, it identified multiple optimization opportunities\n3. Performance optimization is a non-trivial task requiring multiple steps\n4. The todo list helps methodically track improvements across different components\n5. This systematic approach ensures all performance bottlenecks are addressed\n</reasoning>\n</example>\n\n## Examples of When NOT to Use the Todo List\n\n<example>\nUser: How do I print 'Hello World' in Python?\nAssistant: In Python, you can print \"Hello World\" with this simple code:\n\npython\nprint(\"Hello World\")\n\nThis will output the text \"Hello World\" to the console when executed.</assistant>\n\n<reasoning>\nThe assistant did not use the todo list because this is a single, trivial task that can be completed in one step. There's no need to track multiple tasks or steps for such a straightforward request.\n</reasoning>\n</example>\n\n<example>\nUser: What does the git status command do?\nAssistant: The git status command shows the current state of your working directory and staging area. It displays which changes have been staged, which haven't, and which files aren't being tracked by Git. This is a fundamental command for understanding the current state of your repository before making commits.\n\n<reasoning>\nThe assistant did not use the todo list because this is an informational request with no actual coding task to complete. The user is simply asking for an explanation, not for the assistant to perform multiple steps or tasks.\n</reasoning>\n</example>\n\n<example>\nUser: Can you add a comment to the calculateTotal function to explain what it does?\nAssistant: Sure, let me add a comment to the calculateTotal function to explain what it does.\n* Uses the Edit tool to add a comment to the calculateTotal function *\n\n<reasoning>\nThe assistant did not use the todo list because this is a single, straightforward task confined to one location in the code. Adding a comment doesn't require tracking multiple steps or systematic organization.\n</reasoning>\n</example>\n\n<example>\nUser: Run npm install for me and tell me what happens.\nAssistant: I'll run the npm install command for you.\n\n*Executes: npm install*\n\nThe command completed successfully. Here's the output:\n[Output of npm install command]\n\nAll dependencies have been installed according to your package.json file.\n\n<reasoning>\nThe assistant did not use the todo list because this is a single command execution with immediate results. There are no multiple steps to track or organize, making the todo list unnecessary for this straightforward task.\n</reasoning>\n</example>\n\n## Task States and Management\n\n1. **Task States**: Use these states to track progress:\n   - pending: Task not yet started\n   - in_progress: Currently working on (limit to ONE task at a time)\n   - completed: Task finished successfully\n\n   **IMPORTANT**: Task descriptions must have two forms:\n   - content: The imperative form describing what needs to be done (e.g., \"Run tests\", \"Build the project\")\n   - activeForm: The present continuous form shown during execution (e.g., \"Running tests\", \"Building the project\")\n\n2. **Task Management**:\n   - Update task status in real-time as you work\n   - Mark tasks complete IMMEDIATELY after finishing (don't batch completions)\n   - Exactly ONE task must be in_progress at any time (not less, not more)\n   - Complete current tasks before starting new ones\n   - Remove tasks that are no longer relevant from the list entirely\n\n3. **Task Completion Requirements**:\n   - ONLY mark a task as completed when you have FULLY accomplished it\n   - If you encounter errors, blockers, or cannot finish, keep the task as in_progress\n   - When blocked, create a new task describing what needs to be resolved\n   - Never mark a task as completed if:\n     - Tests are failing\n     - Implementation is partial\n     - You encountered unresolved errors\n     - You couldn't find necessary files or dependencies\n\n4. **Task Breakdown**:\n   - Create specific, actionable items\n   - Break complex tasks into smaller, manageable steps\n   - Use clear, descriptive task names\n   - Always provide both forms:\n     - content: \"Fix authentication bug\"\n     - activeForm: \"Fixing authentication bug\"\n\nWhen in doubt, use this tool. Being proactive with task management demonstrates attentiveness and ensures you complete all requirements successfully.\n",
      "input_schema": {
        "type": "object",
        "properties": {
          "todos": {
            "description": "The updated todo list",
            "type": "array",
            "items": {
              "properties": {
                "activeForm": {
                  "minLength": 1,
                  "type": "string"
                },
                "content": {
                  "type": "string",
                  "minLength": 1
                },
                "status": {
                  "enum": [
                    "pending",
                    "in_progress",
                    "completed"
                  ],
                  "type": "string"
                }
              },
              "required": [
                "content",
                "status",
                "activeForm"
              ],
              "additionalProperties": false,
              "type": "object"
            }
          }
        },
        "required": [
          "todos"
        ],
        "additionalProperties": false,
        "$schema": "http://json-schema.org/draft-07/schema#"
      },
      "name": "TodoWrite"
    },
    {
      "name": "WebSearch",
      "description": "\n- Allows Claude to search the web and use the results to inform responses\n- Provides up-to-date information for current events and recent data\n- Returns search result information formatted as search result blocks\n- Use this tool for accessing information beyond Claude's knowledge cutoff\n- Searches are performed automatically within a single API call\n\nUsage notes:\n  - Domain filtering is supported to include or block specific websites\n  - Web search is only available in the US\n  - Account for \"Today's date\" in <env>. For example, if <env> says \"Today's date: 2025-07-01\", and the user wants the latest docs, do not use 2024 in the search query. Use 2025.\n",
      "input_schema": {
        "required": [
          "query"
        ],
        "additionalProperties": false,
        "$schema": "http://json-schema.org/draft-07/schema#",
        "type": "object",
        "properties": {
          "allowed_domains": {
            "type": "array",
            "items": {
              "type": "string"
            },
            "description": "Only include search results from these domains"
          },
          "blocked_domains": {
            "items": {
              "type": "string"
            },
            "description": "Never include search results from these domains",
            "type": "array"
          },
          "query": {
            "minLength": 2,
            "description": "The search query to use",
            "type": "string"
          }
        }
      }
    },
    {
      "name": "BashOutput",
      "description": "\n- Retrieves output from a running or completed background bash shell\n- Takes a shell_id parameter identifying the shell\n- Always returns only new output since the last check\n- Returns stdout and stderr output along with shell status\n- Supports optional regex filtering to show only lines matching a pattern\n- Use this tool when you need to monitor or check the output of a long-running shell\n- Shell IDs can be found using the /bashes command\n",
      "input_schema": {
        "$schema": "http://json-schema.org/draft-07/schema#",
        "type": "object",
        "properties": {
          "bash_id": {
            "description": "The ID of the background shell to retrieve output from",
            "type": "string"
          },
          "filter": {
            "type": "string",
            "description": "Optional regular expression to filter the output lines. Only lines matching this regex will be included in the result. Any lines that do not match will no longer be available to read."
          }
        },
        "required": [
          "bash_id"
        ],
        "additionalProperties": false
      }
    },
    {
      "name": "KillShell",
      "description": "\n- Kills a running background bash shell by its ID\n- Takes a shell_id parameter identifying the shell to kill\n- Returns a success or failure status \n- Use this tool when you need to terminate a long-running shell\n- Shell IDs can be found using the /bashes command\n",
      "input_schema": {
        "$schema": "http://json-schema.org/draft-07/schema#",
        "type": "object",
        "properties": {
          "shell_id": {
            "type": "string",
            "description": "The ID of the background shell to kill"
          }
        },
        "required": [
          "shell_id"
        ],
        "additionalProperties": false
      }
    },
    {
      "input_schema": {
        "required": [
          "questions"
        ],
        "additionalProperties": false,
        "$schema": "http://json-schema.org/draft-07/schema#",
        "type": "object",
        "properties": {
          "questions": {
            "minItems": 1,
            "maxItems": 4,
            "description": "Questions to ask the user (1-4 questions)",
            "type": "array",
            "items": {
              "additionalProperties": false,
              "type": "object",
              "properties": {
                "options": {
                  "minItems": 2,
                  "maxItems": 4,
                  "description": "The available choices for this question. Must have 2-4 options. Each option should be a distinct, mutually exclusive choice (unless multiSelect is enabled). There should be no 'Other' option, that will be provided automatically.",
                  "type": "array",
                  "items": {
                    "properties": {
                      "label": {
                        "type": "string",
                        "description": "The display text for this option that the user will see and select. Should be concise (1-5 words) and clearly describe the choice."
                      },
                      "description": {
                        "description": "Explanation of what this option means or what will happen if chosen. Useful for providing context about trade-offs or implications.",
                        "type": "string"
                      }
                    },
                    "required": [
                      "label",
                      "description"
                    ],
                    "additionalProperties": false,
                    "type": "object"
                  }
                },
                "multiSelect": {
                  "type": "boolean",
                  "description": "Set to true to allow the user to select multiple options instead of just one. Use when choices are not mutually exclusive."
                },
                "question": {
                  "type": "string",
                  "description": "The complete question to ask the user. Should be clear, specific, and end with a question mark. Example: \"Which library should we use for date formatting?\" If multiSelect is true, phrase it accordingly, e.g. \"Which features do you want to enable?\""
                },
                "header": {
                  "description": "Very short label displayed as a chip/tag (max 12 chars). Examples: \"Auth method\", \"Library\", \"Approach\".",
                  "type": "string"
                }
              },
              "required": [
                "question",
                "header",
                "options",
                "multiSelect"
              ]
            }
          },
          "answers": {
            "type": "object",
            "additionalProperties": {
              "type": "string"
            },
            "description": "User answers collected by the permission component"
          }
        }
      },
      "name": "AskUserQuestion",
      "description": "Use this tool when you need to ask the user questions during execution. This allows you to:\n1. Gather user preferences or requirements\n2. Clarify ambiguous instructions\n3. Get decisions on implementation choices as you work\n4. Offer choices to the user about what direction to take.\n\nUsage notes:\n- Users will always be able to select \"Other\" to provide custom text input\n- Use multiSelect: true to allow multiple answers to be selected for a question\n"
    },
    {
      "description": "Execute a skill within the main conversation\n\n<skills_instructions>\nWhen users ask you to perform tasks, check if any of the available skills below can help complete the task more effectively. Skills provide specialized capabilities and domain knowledge.\n\nHow to use skills:\n- Invoke skills using this tool with the skill name only (no arguments)\n- When you invoke a skill, you will see <command-message>The \"{name}\" skill is loading</command-message>\n- The skill's prompt will expand and provide detailed instructions on how to complete the task\n- Examples:\n  - `skill: \"pdf\"` - invoke the pdf skill\n  - `skill: \"xlsx\"` - invoke the xlsx skill\n  - `skill: \"ms-office-suite:pdf\"` - invoke using fully qualified name\n\nImportant:\n- Only use skills listed in <available_skills> below\n- Do not invoke a skill that is already running\n- Do not use this tool for built-in CLI commands (like /help, /clear, etc.)\n</skills_instructions>\n\n<available_skills>\n<skill>\n<name>\nai-ml-expert\n</name>\n<description>\nComprehensive AI/ML expertise covering AI assistant development, LangChain/LangGraph architecture, RAG implementation, and agent optimization. Use for building intelligent conversational interfaces, production-grade agent systems, knowledge-grounded AI, and optimizing AI agent performance. (project, gitignored)\n</description>\n<location>\nuser\n</location>\n</skill>\n<skill>\n<name>\narchitecture-expert\n</name>\n<description>\nComprehensive architecture expertise covering design patterns, microservices architecture, and multi-cloud strategies. Use for system design, architecture decisions, distributed systems, and cloud-agnostic implementations. (project, gitignored)\n</description>\n<location>\nuser\n</location>\n</skill>\n<skill>\n<name>\nbackend-expert\n</name>\n<description>\nComprehensive backend development expertise covering API design, implementation patterns, database operations, and optimization strategies across FastAPI, Node.js, PostgreSQL, and SQL technologies. (project, gitignored)\n</description>\n<location>\nuser\n</location>\n</skill>\n<skill>\n<name>\ncode-review-expert\n</name>\n<description>\nComprehensive code review expertise covering manual reviews, AI-powered analysis, PR optimization, documentation generation, code explanation, and multi-agent orchestration. Use for all code review, PR creation, code explanation, and documentation tasks. (project, gitignored)\n</description>\n<location>\nuser\n</location>\n</skill>\n<skill>\n<name>\ncost-optimization-expert\n</name>\n<description>\nComprehensive cost optimization expertise covering cloud infrastructure, resource rightsizing, storage optimization, network efficiency, container workloads, and automated cost management. Use for all cloud cost reduction initiatives, infrastructure expense analysis, and cost governance implementation. (project, gitignored)\n</description>\n<location>\nuser\n</location>\n</skill>\n<skill>\n<name>\ndata-engineering-expert\n</name>\n<description>\nComprehensive data engineering expertise covering data pipeline architecture, ML workflows, feature development, and end-to-end MLOps orchestration. Use for designing, building, and operating scalable data systems. (project, gitignored)\n</description>\n<location>\nuser\n</location>\n</skill>\n<skill>\n<name>\ndeployment-expert\n</name>\n<description>\nComprehensive deployment expertise covering CI/CD pipeline architecture, GitHub Actions workflows, GitLab CI patterns, and deployment strategies including approval gates, security scanning, and multi-environment orchestration. Use for any deployment automation, pipeline design, or continuous delivery implementation. (project, gitignored)\n</description>\n<location>\nuser\n</location>\n</skill>\n<skill>\n<name>\ndeveloper-productivity-expert\n</name>\n<description>\nComprehensive developer productivity expertise covering context management, onboarding workflows, team communication, and productivity optimization. Use for developer experience optimization, team productivity workflows, knowledge transfer, and async collaboration patterns. (project, gitignored)\n</description>\n<location>\nuser\n</location>\n</skill>\n<skill>\n<name>\nfeature-development-expert\n</name>\n<description>\nComprehensive feature development expertise covering full-stack implementation, issue resolution, and data-driven development workflows. Use for any feature development task from architecture through deployment and optimization. (project, gitignored)\n</description>\n<location>\nuser\n</location>\n</skill>\n<skill>\n<name>\nfrontend-expert\n</name>\n<description>\nComprehensive frontend development expertise covering React modernization, Angular migration, TypeScript advanced patterns, modern JavaScript ES6+, and project scaffolding. Use for all frontend development tasks including framework upgrades, migration projects, type-safe development, and modern JavaScript implementation. (project, gitignored)\n</description>\n<location>\nuser\n</location>\n</skill>\n<skill>\n<name>\ngit-workflow-expert\n</name>\n<description>\nComprehensive Git workflow expertise covering fundamental workflows, advanced Git operations, and GitOps deployment patterns. Use for branching strategies, history management, multi-agent orchestration, and declarative Kubernetes deployments. (project, gitignored)\n</description>\n<location>\nuser\n</location>\n</skill>\n<skill>\n<name>\ninfrastructure-expert\n</name>\n<description>\nComprehensive infrastructure expertise covering Kubernetes manifest generation, Helm chart development, and security policies. Use for building production-ready Kubernetes infrastructure, implementing security hardening, and managing containerized applications at scale. (project, gitignored)\n</description>\n<location>\nuser\n</location>\n</skill>\n<skill>\n<name>\nllm-optimization-expert\n</name>\n<description>\nComprehensive LLM optimization expertise covering prompt engineering, multi-agent orchestration, evaluation frameworks, and performance optimization. Use for optimizing LLM applications, improving prompt effectiveness, coordinating multi-agent systems, measuring AI performance, and implementing evaluation frameworks. (project, gitignored)\n</description>\n<location>\nuser\n</location>\n</skill>\n<skill>\n<name>\nobservability-expert\n</name>\n<description>\nComprehensive observability expertise covering monitoring setup, SLO implementation, distributed tracing, incident response, and systematic debugging. Use for all observability, monitoring, reliability, and debugging tasks. (project, gitignored)\n</description>\n<location>\nuser\n</location>\n</skill>\n<skill>\n<name>\nopenai-agents-js\n</name>\n<description>\nThis skill should be used when building, orchestrating, and operating TypeScript agents with the OpenAI Agents SDK (@openai/agents), including tools, handoffs, guardrails, sessions, models, streaming, tracing, and realtime voice. (project, gitignored)\n</description>\n<location>\nuser\n</location>\n</skill>\n<skill>\n<name>\nrefactoring-expert\n</name>\n<description>\nComprehensive refactoring expertise covering code improvement patterns, legacy modernization, automated fixes, and migration strategies. Use for all code enhancement, modernization, and quality improvement tasks. (project, gitignored)\n</description>\n<location>\nuser\n</location>\n</skill>\n<skill>\n<name>\nrust-paddle-ocr\n</name>\n<description>\nThis skill should be used when integrating the rust-paddle-ocr library into real-world Rust, Tauri, CLI, and FFI projects with clear structure, proven patterns, and copy-pastable examples. (project, gitignored)\n</description>\n<location>\nuser\n</location>\n</skill>\n<skill>\n<name>\nsecurity-expert\n</name>\n<description>\nComprehensive security expertise covering vulnerability scanning, compliance frameworks, dependency security, SAST, XSS protection, security hardening, and regulatory compliance. Use for security auditing, vulnerability assessment, compliance validation, penetration testing, security monitoring, and threat modeling. (project, gitignored)\n</description>\n<location>\nuser\n</location>\n</skill>\n<skill>\n<name>\nskill-creator\n</name>\n<description>\nGuide for creating effective skills. This skill should be used when users want to create a new skill (or update an existing skill) that extends Claude's capabilities with specialized knowledge, workflows, or tool integrations. (project, gitignored)\n</description>\n<location>\nuser\n</location>\n</skill>\n<skill>\n<name>\ntesting-expert\n</name>\n<description>\nComprehensive testing expertise covering TDD workflows, automated test generation, language-specific patterns (JavaScript, Python, Bats), and E2E testing with Playwright/Cypress. Use for all testing-related tasks including test setup, TDD implementation, test automation, and quality assurance. (project, gitignored)\n</description>\n<location>\nuser\n</location>\n</skill>\n</available_skills>\n",
      "input_schema": {
        "$schema": "http://json-schema.org/draft-07/schema#",
        "type": "object",
        "properties": {
          "skill": {
            "type": "string",
            "description": "The skill name (no arguments). E.g., \"pdf\" or \"xlsx\""
          }
        },
        "required": [
          "skill"
        ],
        "additionalProperties": false
      },
      "name": "Skill"
    },
    {
      "name": "SlashCommand",
      "description": "Execute a slash command within the main conversation\n\nHow slash commands work:\nWhen you use this tool or when a user types a slash command, you will see <command-message>{name} is running\u2026</command-message> followed by the expanded prompt. For example, if .claude/commands/foo.md contains \"Print today's date\", then /foo expands to that prompt in the next message.\n\nUsage:\n- `command` (required): The slash command to execute, including any arguments\n- Example: `command: \"/review-pr 123\"`\n\nIMPORTANT: Only use this tool for custom slash commands that appear in the Available Commands list below. Do NOT use for:\n- Built-in CLI commands (like /help, /clear, etc.)\n- Commands not shown in the list\n- Commands you think might exist but aren't listed\n\nNotes:\n- When a user requests multiple slash commands, execute each one sequentially and check for <command-message>{name} is running\u2026</command-message> to verify each has been processed\n- Do not invoke a command that is already running. For example, if you see <command-message>foo is running\u2026</command-message>, do NOT use this tool with \"/foo\" - process the expanded prompt in the following message\n- Only custom slash commands with descriptions are listed in Available Commands. If a user's command is not listed, ask them to check the slash command file and consult the docs.\n",
      "input_schema": {
        "type": "object",
        "properties": {
          "command": {
            "type": "string",
            "description": "The slash command to execute with its arguments, e.g., \"/review-pr 123\""
          }
        },
        "required": [
          "command"
        ],
        "additionalProperties": false,
        "$schema": "http://json-schema.org/draft-07/schema#"
      }
    }
  ],
  "thinking": {
    "budget_tokens": 4096,
    "type": "enabled"
  },
  "temperature": 1
}